{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Apply Neural Networks to the Stock Market\n",
    "\n",
    "Notebook to explore limited set of NY stock exchange data over around 40 years, as part of the Portland Data Science group (Mar 2018).\n",
    "Data selected by Matt Borthwick from Yahoo! Finance.\n",
    "Working with Neural Network group: Matt, John Burt, Manny, Isil, Kenny, Jhoan, Mark C.\n",
    "\n",
    "Our goal is to predict weekly returns on 6 industry based ETFs, as well\n",
    "as aggregate market performance (such as Russel3000).  We will also\n",
    "be using some macroeconomic indicators as well.\n",
    "This notebook currently loads the data, transforms it, and applies a\n",
    "simple neural network to try predicting the next days stock prices.\n",
    "\n",
    "The plan is to train on this data (up to Sep 2017),\n",
    "validate on (Oct-Dec 2017), and test in final session on (Jan-Mar 2018).\n",
    "\n",
    "(For more exploratory screwing around, and other attempts at time-series see PDX_finance1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# automatically reload files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Data compiled from Yahoo! Finance data by Matt Borthwick\n",
    "df=pd.read_csv('data/stocks-us-adjClose.csv',index_col=0,parse_dates=True)\n",
    "df.index.name='Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  ED        DD       CVX        FL       CAT        IP  SJW  \\\n",
       "Time                                                                          \n",
       "1970-01-02  0.307997  0.000480  0.582503  1.857836  1.475225  1.808415  NaN   \n",
       "1970-01-05  0.320831  0.000481  0.585290  1.839623  1.470783  1.873423  NaN   \n",
       "1970-01-06  0.316553  0.000477  0.576929  1.845694  1.435234  1.855694  NaN   \n",
       "1970-01-07  0.312275  0.000475  0.575535  1.809266  1.390800  1.814324  NaN   \n",
       "1970-01-08  0.312275  0.000469  0.586683  1.821408  1.395244  1.832054  NaN   \n",
       "\n",
       "             F  LLY  AVP ...   EXTN  VYGR  ACG  MIME  TCRZ  MCX  EDIT  LMHA  \\\n",
       "Time                     ...                                                  \n",
       "1970-01-02 NaN  NaN  NaN ...    NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1970-01-05 NaN  NaN  NaN ...    NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1970-01-06 NaN  NaN  NaN ...    NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1970-01-07 NaN  NaN  NaN ...    NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1970-01-08 NaN  NaN  NaN ...    NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "            UA  BTU  \n",
       "Time                 \n",
       "1970-01-02 NaN  NaN  \n",
       "1970-01-05 NaN  NaN  \n",
       "1970-01-06 NaN  NaN  \n",
       "1970-01-07 NaN  NaN  \n",
       "1970-01-08 NaN  NaN  \n",
       "\n",
       "[5 rows x 710 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "This model is just a test based purely on the stock data.\n",
    "The network uses a multi-layer RNN, with two hidden layers at input/output.  They use leaky ReLU activation.\n",
    "The model currently plays with 100 stocks from 2002-2006.\n",
    "\n",
    "This uses a model I've cobbled together in Tensorflow.\n",
    "The OO structure is borrowed from the online problem sets\n",
    "from CS224 on NLP offered in 2017 at Stanford.\n",
    "The NN is borrowed from A. Geron \"Hands on Machine Learning with Scikit-Learn and Tensorflow\", which I've found to be the best\n",
    "overall introduction, and has a good mix of background, and code.\n",
    "(Note there is an associated Github account with code).\n",
    "\n",
    "The Tensorflow docs were pretty hard reading, and there seem to be lots\n",
    "of tricks that only practitioners on StackOverflow are aware of.  (But the tutorials are pretty readable.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from recurrent_network import recurrent_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#Data Transformation\n",
    "\n",
    "For the initial testing, I'm just building a model based on the 100 oldest stocks (or whichever come first), and looking at 2002-2006.\n",
    "The model is trained on the first half of the data, and we then run the\n",
    "network on the whole data set.  \n",
    "\n",
    "I'm currently just taking the base-10 log of the data, and scaling each\n",
    "stock to lie with [-1,1].  I found differencing the data lead to\n",
    "pretty crappy results.\n",
    "\n",
    "So there's some choices to be played with here:\n",
    "- scaling: variance vs max/min\n",
    "- differencing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#grab 100 stocks from 2003/2004 for quick testing.\n",
    "#Why 2004? Because I think the market is fairly well behaved then.\n",
    "#Or at least, not crashing.\n",
    "Nstocks=100\n",
    "Xsub=df.loc['2002':'2006'].iloc[:,:Nstocks].values\n",
    "\n",
    "#set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "Xsub[np.isnan(Xsub)]=0\n",
    "\n",
    "#take differences of logs. (shift zero to avoid NANs)\n",
    "#Xsub2 = np.diff(np.log10(Xsub+1E-12),axis=0)\n",
    "Xsub2 = np.log10(Xsub+1E-12)\n",
    "\n",
    "Xsub_max = np.max(Xsub2,axis=0)\n",
    "Xsub_min = np.min(Xsub2,axis=0)\n",
    "\n",
    "#Choice of scaling here: max/min vs variance?\n",
    "#I think variance makes more sense if differencing.\n",
    "rng = 0.5*(Xsub_max-Xsub_min)\n",
    "avg = 0.5*(Xsub_max+Xsub_min)\n",
    "Xsub2= (Xsub2-avg)/rng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba63563c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check scaling\n",
    "plt.figure()\n",
    "plt.plot(Xsub2[:,0:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#define network.\n",
    "RNN=recurrent_NN(60,Nstocks,100,Nstocks,'GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba61db8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #200. Current MSE:0.006905854679644108\n",
      "Total Time taken:101.30108571052551\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rebuild the tensorflow graph.\n",
    "RNN.build()\n",
    "#Actually train the graph on first half of data.\n",
    "#Give all of the data to this subroutine, where it selects\n",
    "# the inputs and target data in get_random_batch\n",
    "\n",
    "N=len(Xsub2)\n",
    "Nc=int(N/2)\n",
    "Xtrain = Xsub2[:Nc]\n",
    "RNN.train_graph(Xtrain,Xtrain,save_name='tf_models/rnn_test')\n",
    "#Note the tiny, tiny errors.  Probably badly overfitting.\n",
    "#Need to fix the dropout so it's only on in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 1000\n",
      "1000 1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 800\n",
      "800 900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 600\n",
      "600 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 400\n",
      "400 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200\n",
      "200 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_models/rnn_test-200\n"
     ]
    }
   ],
   "source": [
    "#Predict on all of the data.\n",
    "#This loads up a previous model.\n",
    "RNN_pred=RNN.predict_all('tf_models/rnn_test',200,Xsub2,reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pred(X,pred,indx_range):\n",
    "    \"\"\"Plots a particular stock and the prediction\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.plot(X[:,indx_range])\n",
    "    plt.plot(pred[:,indx_range])\n",
    "    plt.plot([len(X)/2]*2,[-1,1],'k-')\n",
    "    plt.legend(['Actual','Forecast'])\n",
    "    plt.title('Raw')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(np.cumsum(X[:,indx_range],axis=0))\n",
    "    plt.plot(np.cumsum(pred[:,indx_range],axis=0))\n",
    "    plt.legend(['Actual','Forecast'])    \n",
    "    plt.title('Cumulative')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9d0cd400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Could make predicted results a time series for nicer formating, and dates.\n",
    "#Plot cumulative for cases when we've also differenced.\n",
    "plot_pred(Xsub2,RNN_pred,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Note the effect of further smoothing, which suggests a clearer trend, that might be easier to model.\n",
    "That suggests the convolutional networks may be useful,\n",
    "perhaps with running averages to smooth the data.  Forecasting on a week timescale might allevative some of that too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9cf63048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's look at the differences between the predicted and actual\n",
    "#results at the end of the period.\n",
    "pred_diff=RNN_pred[-1]-Xsub2[-1]\n",
    "plt.hist(pred_diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'skew'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-e41535a6c360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'skew'"
     ]
    }
   ],
   "source": [
    "(np.mean(pred_diff),np.std(pred_diff),np.skew(pred_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9cc874e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's now see how it does for a month out.\n",
    "Nc = int(len(Xsub2)/2)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(131)\n",
    "pred_diff=RNN_pred[Nc]-Xsub2[Nc]\n",
    "plt.title('End of training')\n",
    "plt.hist(pred_diff)\n",
    "\n",
    "\n",
    "plt.subplot(132)\n",
    "pred_diff=RNN_pred[Nc+20]-Xsub2[Nc+20]\n",
    "plt.title('End of training+20 days')\n",
    "plt.hist(pred_diff)\n",
    "\n",
    "plt.subplot(133)\n",
    "pred_diff=RNN_pred[-1]-Xsub2[-1]\n",
    "plt.hist(pred_diff)\n",
    "plt.title('End of test (2006)')\n",
    "plt.xlabel('Forecast Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "An earlier simple RNN was over optimistic, this seems to do better (in terms of not being too biased).\n",
    "\n",
    "The final graph is worst, it is also trying to predict many years ahead, based on essentially short-term info.\n",
    "Probably could describe build up of cumulative errors as a random walk?\n",
    "Would guess errors grows as sqrt(T), so the variance of this distribution grows as T.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Checking my batching was finding the right things.\n",
    "#Looks plausible.\n",
    "xi,yi=RNN.get_random_batch(Xsub2,Xsub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86257978  0.88103946  0.86054468  0.87236487  0.87699467  0.8733055   0.88605149  0.8815979   0.89817284  0.91405475]\n",
      "0.906092957954\n"
     ]
    }
   ],
   "source": [
    "batch_no=1\n",
    "stock_no=1\n",
    "print(xi[batch_no,-10:,stock_no])\n",
    "print(yi[batch_no,stock_no])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "PDX_finance.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
