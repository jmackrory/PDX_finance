{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Apply Neural Networks to the Stock Market\n",
    "\n",
    "Notebook to explore limited set of NY stock exchange data over around 40 years, as part of the Portland Data Science group (Mar 2018).\n",
    "Data selected by Matt Borthwick from Yahoo! Finance.\n",
    "Working with Neural Network group: Matt, John Burt, Manny, Isil, Kenny, Jhoan, Mark C.\n",
    "\n",
    "Our goal is to predict weekly returns on 6 industry based ETFs, as well\n",
    "as aggregate market performance (such as Russel3000).  We will also\n",
    "be using some macroeconomic indicators as well.\n",
    "This notebook currently loads the data, transforms it, and applies a\n",
    "simple neural network to try predicting the next days stock prices.\n",
    "The first model was built in tensorflow (and is currently broken).  THere is a second network written in Keras.\n",
    "\n",
    "The plan is to train on this data (up to Sep 2017),\n",
    "validate on (Oct-Dec 2017), and test in final session on (Jan-Mar 2018).\n",
    "\n",
    "(For more exploratory screwing around, and other attempts at time-series see PDX_finance1)\n",
    "\n",
    "Currently Contains:\n",
    "-Colab setup\n",
    "-Loading data\n",
    "-Tensorflow RNN (currently borked at prediction stage - wrong size? No idea what changed)\n",
    "-Keras RNN  (not working yet)\n",
    "-Keras Deep network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Google Colab setup\n",
    "\n",
    "First up however, we need to install modules to load up our google drive for storage.  (Code taken from this helpful post https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
    "(Code and commands didn't look sketchy/malicious, but I didn't examine the PPA too closely either.)\n",
    "\n",
    "This code is for execution inside a Jupyter notebook on colab.google.com.\n",
    "It gives Colab access to your Google Drive in order to load/save data from within the notebook.\n",
    "Colab has most popular libraries (numpy, pandas, tensorflow, matplotlib).  I'm not sure how extensive it is.\n",
    "\n",
    "I've found opening a jupyter notebook on google drive automatically opens the Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Install modules on local machine.\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!echo 'past update'\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "!echo 'installed fuse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "print('past first command')\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Mounts google drive, and changes to that directory\n",
    "!mkdir -p drive \n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "import os\n",
    "os.chdir(\"drive\")\n",
    "\n",
    "#Should now be in the root of your google-drive, and now free to load/save existing files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Load Libraries and Data\n",
    "\n",
    "Now to load libraries, and data for all stocks, ETFs, and indicators.\n",
    "All of those will get stuck together into one total dataframe.\n",
    "(This is where I start my analysis on my home machine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "# automatically reload files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_stock_data():\n",
    "\n",
    "    #Data compiled from Yahoo! Finance data by Matt Borthwick\n",
    "    df_close=pd.read_csv('data/stocks-us-adjClose.csv',index_col=0,parse_dates=True)\n",
    "    df_open=pd.read_csv('data/stocks-us-adjOpen.csv',index_col=0,parse_dates=True)\n",
    "    df_high=pd.read_csv('data/stocks-us-adjHigh.csv',index_col=0,parse_dates=True)\n",
    "    df_low=pd.read_csv('data/stocks-us-adjLow.csv',index_col=0,parse_dates=True)\n",
    "    df_vol=pd.read_csv('data/stocks-us-Volume.csv',index_col=0,parse_dates=True)\n",
    "    df_close.index.name='date'\n",
    "    df_open.index.name='date'\n",
    "    df_high.index.name='date'\n",
    "    df_low.index.name='date'\n",
    "    df_vol.index.name='date'\n",
    "\n",
    "    #Follow Leffers and rename columns.\n",
    "    df_close_new=[];\n",
    "    df_open_new=[];\n",
    "    df_low_new=[];\n",
    "    df_high_new=[];\n",
    "    df_vol_new=[];\n",
    "\n",
    "    for name in df_close.columns:\n",
    "        df_close_new.append(name+'close')\n",
    "\n",
    "    for name in df_open.columns:\n",
    "        df_open_new.append(name+'open')\n",
    "\n",
    "    for name in df_low.columns:\n",
    "        df_low_new.append(name+'low')\n",
    "\n",
    "    for name in df_high.columns:\n",
    "        df_high_new.append(name+'high')\n",
    "\n",
    "    for name in df_vol.columns:\n",
    "        df_vol_new.append(name+'vol')\n",
    "\n",
    "    df_close.columns=df_close_new\n",
    "    df_open.columns=df_open_new\n",
    "    df_low.columns=df_low_new\n",
    "    df_high.columns=df_high_new\n",
    "    df_vol.columns=df_vol_new\n",
    "\n",
    "    #join all stocks together.\n",
    "    df_stock=df_close.join(df_open,how='inner')\n",
    "    df_stock=df_stock.join(df_high,how='inner')\n",
    "    df_stock=df_stock.join(df_low,how='inner')\n",
    "    df_stock=df_stock.join(df_vol,how='inner')\n",
    "\n",
    "    return df_stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_etfs():\n",
    "    \"\"\"load_etfs\n",
    "    Create combined ETF/RUA data.\n",
    "    Uses initial training data data up to Sep 2017.\n",
    "    Augmented to also load up data from Sep-Dec 2017.\n",
    "    \"\"\"\n",
    "    # df_etf = pd.read_csv('data/sector_ETFs.csv',index_col=0,parse_dates=True)\n",
    "    # #latest ETFs include ^RUA.\n",
    "    # df_etf2 = pd.read_csv('data/sector_etfs-2-corrected.csv',index_col=0,parse_dates=True)\n",
    "    # df_etf=df_etf.append(df_etf2)\n",
    "    # df_rua=pd.read_csv('data/market.csv',index_col=0,parse_dates=True)\n",
    "    # df_rua.columns=['Market (^RUA)']\n",
    "    # df_etf.update(df_rua,overwrite=True)\n",
    "\n",
    "    df_etf=pd.read_csv('data/sector_etfs3.csv',index_col=0,parse_dates=True)\n",
    "\n",
    "    return df_etf\n",
    "\n",
    "def clean_new_etfs(etf_cols):\n",
    "    \"\"\"clean_new_etfs\n",
    "    Loads up ETF/RUA from Sep2017 to Apr 2018.\n",
    "    Fills in missing NA via first replacing with median, then taking \n",
    "    average of neighbouring points.\n",
    "    Note: Off by 1% from earlier values.  \n",
    "    \"\"\"\n",
    "    df_tot=pd.DataFrame()\n",
    "    for etf_name in etf_cols:\n",
    "        #match via regex\n",
    "        mc=re.search('\\(([A-Z\\^]+)\\)',etf_name)\n",
    "        #retrieve the match\n",
    "        etf_ticker=mc.group(1)      \n",
    "        df=pd.read_csv('data/latest_etf/'+etf_ticker+'.csv', index_col=0,parse_dates=True,na_values='null')\n",
    "        df.rename(columns={'Adj Close':etf_name},inplace=True)\n",
    "        #only join based on adjusted close\n",
    "\n",
    "        #Kill missing values via linear interpolation.\n",
    "        ser=df.iloc[:,4].copy()\n",
    "        msk=np.isnan(ser.values)\n",
    "        ind=np.arange(len(ser))[msk]\n",
    "        #replace multiple NA with median.\n",
    "        ser[msk]=ser.median()\n",
    "        #for isolated values, replace by the average on either side.    \n",
    "        for i in ind:\n",
    "            ser.iloc[i]=(ser.iloc[i-1]+ser.iloc[i+1])/2\n",
    "        ser.reindex(df.index )\n",
    "        df_tot=df_tot.join(ser,how='outer')\n",
    "    return df_tot    \n",
    "    \n",
    "def load_indicators(tag='Train'):\n",
    "    \"\"\"load_indicators\n",
    "    Based on Matt Leffers code for reading in indicators.\n",
    "    Adjusted to also use a tag for train/test.  \n",
    "    \"\"\"\n",
    "    \n",
    "    # remove warnings\n",
    "    import csv\n",
    "    import warnings\n",
    "\n",
    "    ##Pieter Leffer's code for reading in indicators\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Leffers ran into errors importing the file because of non-ascii characters in the heading\n",
    "    #Here is a piece of code Leffers got from stack overflow to fix that problem.\n",
    "    df_ind=[]\n",
    "    with open('data/Indicators_'+tag+'.csv', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            df_ind.append(row)\n",
    "\n",
    "    df_ind=pd.DataFrame(df_ind)\n",
    "    df_ind.columns=df_ind.iloc[0]\n",
    "    Column_Reference=df_ind.iloc[1].copy()\n",
    "    print(df_ind.columns)\n",
    "    #Drop useless rows (last row is empty)\n",
    "    df_ind.drop([0,1],axis=0,inplace=True)\n",
    "\n",
    "    # #Change the formatting of the variables. Datetime to the ones for dates, integers for the ones that aren't\n",
    "    for i in range(0,len(df_ind.columns)):\n",
    "        col_name=df_ind.columns[i]\n",
    "        if re.search('_dt',col_name):\n",
    "            df_ind[col_name] = pd.to_datetime(df_ind[col_name],  format = '%m/%d/%Y',  errors='coerce')\n",
    "            #print(col_name,'time')\n",
    "        else:\n",
    "            df_ind[col_name] = pd.to_numeric(df_ind[col_name], errors='ignore')\n",
    "            #print(col_name,'val')\n",
    "\n",
    "    # #Reset the index because we dropped rows in the DataFrame, Using the drop command to remove the old index\n",
    "    df_ind.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # #make a time index too.\n",
    "    df_ind.index=pd.DatetimeIndex(df_ind['date'])\n",
    "\n",
    "    # #drop all NaTs\n",
    "    msk=np.isnat(df_ind.index)\n",
    "    df_ind=df_ind[~msk]\n",
    "    df_ind.drop(df_ind.columns[[0,1]],axis=1,inplace=True)\n",
    "    return df_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_etf=load_etfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc784704588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_etf['2018'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "etf_cols=['Technology (IYW)', 'Basic Materials (IYM)', 'Consumer Goods (IYK)',\n",
    "       'Services (IYC)', 'Healthcare (IYH)', 'Utilities (IDU)',\n",
    "       'Market (^RUA)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-71545851a22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mind_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ind' is not defined"
     ]
    }
   ],
   "source": [
    "ind_col=df_ind.columns\n",
    "\n",
    "for col_name in ind_col:\n",
    "    if re.search('_dt',col_name):\n",
    "       print(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#loads stock data up to Sep 2017.\n",
    "df_stocks=load_stock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#load ETFs/RUA up to Apr2018\n",
    "df_target=load_etfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['', 'date', 'HOUST', 'HOUST_dt', 'UNRATENSA', 'UNRATENSA_dt', 'EMRATIO',\n",
      "       'EMRATIO_dt', 'UEMPMED', 'UEMPMED_dt', 'UMCSENT', 'UMCSENT_dt',\n",
      "       'USSLIND', 'USSLIND_dt', 'KCFSI', 'KCFSI_dt', 'IPMAN', 'IPMAN_dt',\n",
      "       'VIXCLS', 'VIXCLS_dt', 'DGS10', 'DGS10_dt'],\n",
      "      dtype='object', name=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['', 'date', 'HOUST', 'HOUST_dt', 'UNRATENSA', 'UNRATENSA_dt', 'EMRATIO',\n",
      "       'EMRATIO_dt', 'UEMPMED', 'UEMPMED_dt', 'UMCSENT', 'UMCSENT_dt',\n",
      "       'USSLIND', 'USSLIND_dt', 'KCFSI', 'KCFSI_dt', 'IPMAN', 'IPMAN_dt',\n",
      "       'VIXCLS', 'VIXCLS_dt', 'DGS10', 'DGS10_dt'],\n",
      "      dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "#load all indicators up to Apr2018\n",
    "df_ind_train=load_indicators(tag='Train')\n",
    "df_ind_test=load_indicators(tag='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HOUST', 'UNRATENSA', 'EMRATIO', 'UEMPMED', 'UMCSENT', 'USSLIND',\n",
      "       'KCFSI', 'IPMAN', 'VIXCLS', 'DGS10'],\n",
      "      dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "df_ind=df_ind_train.append(df_ind_test)\n",
    "#drop duplicate rows/days\n",
    "drop_msk=df_ind.index.duplicated() #|(df_ind.index.dayofweek>=5)  \n",
    "df_ind.drop(df_ind.index[drop_msk],inplace=True)\n",
    "\n",
    "#append indicators to end of dataframe.\n",
    "drop_col_num=df_ind.columns.str.contains('[date]|[_dt]')\n",
    "keep_col    =df_ind.columns[~drop_col_num]\n",
    "print(keep_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17347, 20)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#join all stocks together.\n",
    "df_tot=df_target.join(df_ind.loc[:,keep_col],how='left')\n",
    "df_tot=df_tot.join(df_stocks,how='left')\n",
    "\n",
    "#drop weekends.\n",
    "# msk=df_tot.index.dayofweek>=5\n",
    "# df_tot.drop(df_tot.index[msk],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Technology (IYW)  Basic Materials (IYM)  Consumer Goods (IYK)  \\\nDate                                                                        \n2018-04-02        164.263974              94.309595            116.571445   \n2018-04-03        165.967538              95.603845            118.541439   \n2018-04-04        168.512877              96.075393            120.692352   \n2018-04-05        168.933756              98.332804            121.566783   \n2018-04-06        164.915347              96.045296            119.938527   \n\n            Services (IYC)  Healthcare (IYH)  Utilities (IDU)  Market (^RUA)  \\\nDate                                                                           \n2018-04-02      177.337173        168.670835       127.237740    1530.280029   \n2018-04-03      179.281295        171.458616       127.832407    1549.329956   \n2018-04-04      182.167438        173.865343       128.064221    1566.950000   \n2018-04-05      184.311998        173.845283       129.132595    1578.020020   \n2018-04-06      180.574052        169.412911       128.094456    1544.279297   \n\n             HOUST  UNRATENSA  EMRATIO   ...    EXTNvol  VYGRvol  ACGvol  \\\nDate                                     ...                               \n2018-04-02     NaN        NaN      NaN   ...        NaN      NaN     NaN   \n2018-04-03     NaN        NaN      NaN   ...        NaN      NaN     NaN   \n2018-04-04  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-04-05  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-04-06  1236.0        4.1     60.4   ...        NaN      NaN     NaN   \n\n            MIMEvol  TCRZvol  MCXvol  EDITvol  LMHAvol  UAvol  BTUvol  \nDate                                                                   \n2018-04-02      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-03      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-04      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-05      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-06      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n\n[5 rows x 3567 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#keep numbers of Stocks, ETFS, indicators.\n",
    "Nstocks_tot=int(df_stocks.shape[1]/5)\n",
    "Netf=7\n",
    "Nind=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make vectors of indices in total to extract together.\n",
    "ind_ind=np.arange(Netf,Netf+Nind)\n",
    "etf_ind=np.arange(0,Netf)\n",
    "Npre=Netf+Nind\n",
    "close_ind=Npre+np.arange(0,Nstocks_tot)\n",
    "open_ind=Npre+np.arange(Nstocks_tot,2*Nstocks_tot)\n",
    "high_ind=Npre+np.arange(2*Nstocks_tot,3*Nstocks_tot)\n",
    "low_ind=Npre+np.arange(3*Nstocks_tot,4*Nstocks_tot)\n",
    "vol_ind=Npre+np.arange(4*Nstocks_tot,5*Nstocks_tot)\n",
    "\n",
    "#make global array of indices to take logs/differences of\n",
    "#take differences for stock prices and ETF data\n",
    "diff_ind = np.append(etf_ind,Npre+np.arange(4*Nstocks_tot))\n",
    "#take logs for stock prices, volumes and ETFs.\n",
    "log_ind = np.append(etf_ind,Npre+np.arange(5*Nstocks_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Technology (IYW)  Basic Materials (IYM)  Consumer Goods (IYK)  \\\nDate                                                                        \n2018-03-23        166.027662              94.901534            116.008584   \n2018-03-26        172.811872              96.687404            117.857971   \n2018-03-27        166.618911              95.694137            117.435823   \n2018-03-28        164.955425              94.480153            118.189648   \n2018-03-29        168.562985              96.396447            119.516387   \n2018-04-02        164.263974              94.309595            116.571445   \n2018-04-03        165.967538              95.603845            118.541439   \n2018-04-04        168.512877              96.075393            120.692352   \n2018-04-05        168.933756              98.332804            121.566783   \n2018-04-06        164.915347              96.045296            119.938527   \n\n            Services (IYC)  Healthcare (IYH)  Utilities (IDU)  Market (^RUA)  \\\nDate                                                                           \n2018-03-23      180.393662        169.593408       124.536558    1536.270020   \n2018-03-26      185.434380        173.213514       125.836754    1576.500000   \n2018-03-27      181.876826        171.037442       127.600585    1549.020020   \n2018-03-28      180.343567        171.899849       127.771928    1544.780029   \n2018-03-29      182.708597        173.093184       128.457302    1565.560059   \n2018-04-02      177.337173        168.670835       127.237740    1530.280029   \n2018-04-03      179.281295        171.458616       127.832407    1549.329956   \n2018-04-04      182.167438        173.865343       128.064221    1566.950000   \n2018-04-05      184.311998        173.845283       129.132595    1578.020020   \n2018-04-06      180.574052        169.412911       128.094456    1544.279297   \n\n             HOUST  UNRATENSA  EMRATIO   ...    EXTNvol  VYGRvol  ACGvol  \\\nDate                                     ...                               \n2018-03-23  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-03-26  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-03-27  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-03-28  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-03-29  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-04-02     NaN        NaN      NaN   ...        NaN      NaN     NaN   \n2018-04-03     NaN        NaN      NaN   ...        NaN      NaN     NaN   \n2018-04-04  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-04-05  1236.0        4.4     60.4   ...        NaN      NaN     NaN   \n2018-04-06  1236.0        4.1     60.4   ...        NaN      NaN     NaN   \n\n            MIMEvol  TCRZvol  MCXvol  EDITvol  LMHAvol  UAvol  BTUvol  \nDate                                                                   \n2018-03-23      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-03-26      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-03-27      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-03-28      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-03-29      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-02      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-03      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-04      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-05      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n2018-04-06      NaN      NaN     NaN      NaN      NaN    NaN     NaN  \n\n[10 rows x 3567 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Old version\n",
    "# df_tot=df_stocks.join(df_ind.loc[df_stocks.index,keep_col],how='left')\n",
    "# df_tot=df_tot.join(df_target,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#dump dataframe as pickle object for ease.\n",
    "file_name='data/df_tot_train.pickle'\n",
    "fileObj=open(file_name,'wb')\n",
    "pickle.dump(df_tot,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Looking at the number of NA values (summed across columns) suggests that\n",
    "there are missing values in these stocks.\n",
    "\n",
    "Could set all NA to zero, then apply linear interpolation to handle isolated missing days.  Let's check the pattern of missing days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29b53cba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot pattern of NA values.  Weird stripes?\n",
    "plt.figure(figsize=(10,6))\n",
    "col=df_close.columns[0:]\n",
    "plt.imshow(np.isnan(df_vol.loc['2000':,col]),aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Data Transformation\n",
    "\n",
    "For the initial testing, I'm just building a model based on the 100 oldest stocks (or whichever come first), and looking at 2002-2006.\n",
    "Why then?  Because it looks relatively well behaved.\n",
    "The model is trained on the first half of the data, and we then run the\n",
    "network on the whole data set.\n",
    "\n",
    "I'm currently just taking the base-10 log of the data, and scaling each\n",
    "stock to lie with [-1,1].  I found differencing the data lead to\n",
    "pretty crappy results (then again, these are also pretty crap results).\n",
    "\n",
    "So there's some choices to be played with here:\n",
    "- scaling: variance vs max/min\n",
    "- differencing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def take_log10(X,log_ind):\n",
    "    \"\"\"take_log10(X)\n",
    "    Takes base10-log of X.  Sets NaN to zero, and shifts zero values by 1E-16.\n",
    "    \"\"\"\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    y=X.copy()\n",
    "    y[np.isnan(y)]=0    \n",
    "    #take logs. (shift zero to avoid NANs)\n",
    "    y[:,log_ind] = np.log10(y[:,log_ind]+1E-16)\n",
    "    return y\n",
    "\n",
    "def scale_maxmin(X,log_ind):\n",
    "    \"\"\"scale_maxmin\n",
    "\n",
    "    Scales each price column by taking log, and max/min scaling.\n",
    "    Takes log of open/high/low/volumes/etf.\n",
    "    Does not take log of indicators.\n",
    "    Max-min scales all of them.\n",
    "    \"\"\"\n",
    "    y=take_log10(X,log_ind)\n",
    "    y_max = np.nanmax(y,axis=0)\n",
    "    y_min = np.nanmin(y,axis=0)\n",
    "    #compute middle and differences of the max/min.\n",
    "    avg = 0.5*(y_max+y_min)\n",
    "    rng = 0.5*(y_max-y_min)\n",
    "    #scale to [-1,+1]\n",
    "    yscaled= (y-avg)/rng\n",
    "    return yscaled,rng,avg\n",
    "\n",
    "def rescale_maxmin_log(Xscaled,avg,rng,log_ind):\n",
    "    \"\"\"rescale_maxmin\n",
    "\n",
    "    Undoes log-max/min scaling. \n",
    "    First undoes max/min scaling.  \n",
    "    Then exponentiates all variables which had log taken.\n",
    "\n",
    "    Input: Xscaled (nrow, ncol) np.array of scaled values\n",
    "           avg (ncol) np.array of average/mean values to shift by\n",
    "           rng (ncol) np.array of standard devations to scale by\n",
    "           \n",
    "    \"\"\"\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    X= avg + rng*Xscaled\n",
    "    #take logs. (shift zero to avoid NANs)\n",
    "    X[:,log_ind] = 10**X[:,log_ind]\n",
    "    return X\n",
    "\n",
    "def scale_diff_var(X,log_ind,diff_ind):\n",
    "    \"\"\"scale_diff_var\n",
    "    Scales each column by taking log, then differencing.\n",
    "    Then scales to have zero mean, and unit standard deviation..\n",
    "    Takes log of all data.\n",
    "    \"\"\"\n",
    "    y=take_log10(X,log_ind)\n",
    "    #take differences logs. (shift zero to avoid NANs)    \n",
    "    y[:,diff_ind] = np.diff(y[:,diff_ind],axis=0)\n",
    "    y_std = np.nanstd(y,axis=0)\n",
    "    y_mean = np.nanmean(y,axis=0)\n",
    "    yscaled= (y-y_mean)/y_std\n",
    "    return yscaled,y_mean,y_std\n",
    "\n",
    "def scale_diff_iqr(X,diff_ind,log_ind):\n",
    "    \"\"\"scale_diff_var\n",
    "    Scales each column by taking log, then differencing.\n",
    "    Then scales to have zero median, and so 95% inter-quartile range is unity.\n",
    "    Should handle the long-tail distributions we will encounter\n",
    "    with some grace.  \n",
    "    Only take the log for the stock/etf data.\n",
    "    \"\"\"\n",
    "\n",
    "    y=take_log10(X,log_ind)\n",
    "    #take differences logs. (shift zero to avoid NANs)\n",
    "    nrow,ncol=y.shape\n",
    "    y2=np.zeros((nrow-1,ncol))\n",
    "    y2[:,diff_ind] = np.diff(y[:,diff_ind],axis=0)\n",
    "    y2[:,~diff_ind] = y[1:,~diff_ind]\n",
    "\n",
    "    keep_msk=(y2==y2)\n",
    "    # print(keep_msk.shape,y2[keep_msk].shape)\n",
    "    X_025 = np.nanpercentile(y2,q=2.5,axis=0)\n",
    "    X_975 = np.nanpercentile(y2,q=97.5,axis=0)\n",
    "    X_range = X_975-X_025\n",
    "    print(X_range[:5])\n",
    "    X_median = np.nanmedian(y2,axis=0)\n",
    "    print(X_median[:5])\n",
    "    Xscaled=np.where(keep_msk, (y2-X_median)/X_range,0)\n",
    "    return Xscaled,X_median,X_range\n",
    "\n",
    "def rescale_diff_iqr(Xscaled,mu,sd,x0,log_ind,diff_ind):\n",
    "    \"\"\"rescale_diffvar\n",
    "\n",
    "    Undoes log-max/min scaling. \n",
    "    Takes log of open/high/low/volumes/etf.\n",
    "    Does not take log of indicators.\n",
    "    Max-min scales all of them.\n",
    "    Only take the log for the stock/etf data.\n",
    "    \"\"\"\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    X= mu + sd*Xscaled\n",
    "    X= np.insert(X,0,x0,axis=0)\n",
    "    X[:,diff_ind] = np.cumsum(X[:,diff_ind],axis=0)\n",
    "    #take logs. (shift zero to avoid NANs)\n",
    "    X[:,log_ind] = 10**X[:,log_ind]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3],\n       [3, 3, 3]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(np.arange(9).reshape(3,3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00044721  0.00040349  0.00030301  0.00029244  0.00027142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03118747  0.03034051  0.01700173  0.02318996  0.01905181]\n"
     ]
    }
   ],
   "source": [
    "Xsub=df_tot['2001':'2004'].values\n",
    "tsub=df_tot['2001':'2004'].index\n",
    "Xsub_scale,Xsub_rng, Xsub_avg=scale_diff_iqr(Xsub,diff_ind,log_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(Xsub_scale[:,8]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan, ...,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsub_scale[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc75d24b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(Xsub_scale[:,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc75d8348d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Xsub_scale[:,0:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(Xtrain).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I had hoped Keras would automatically take care of random temporal batching like this, but unfortunately it does not.\n",
    "So, this routine which randomly selects a batch of indices to start fitting at.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Making the Network\n",
    "\n",
    "The following makes a 4 layer network - a dense layer at input with linear activation to reduce dimension,\n",
    "followed by two recurrent layers (using a LSTM for longer memory),\n",
    "and a final dense layer to map from the hidden units to the final outputs.\n",
    "The LSTMs can use \"leaky ReLU\" activation, which are suited to long sequences since the gradients dont explode, or go to zero.\n",
    "The output sequences are then flattened, before being put through\n",
    "a final linear layer to add together the results.\n",
    "(In a fancy version this could be a CNN?)\n",
    "The final result is reshaped again to output a batch of sequences.\n",
    "\n",
    "The Adam optimizer is basically a fancy version of gradient descent (with a momentum, scaling based on previous updates, and learning rate scheduling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from neural_networks.KerasRecurrentNetwork import KerasRecurrentNetwork, RNNConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "keras_conf=RNNConfig()\n",
    "Keras_RNN=KerasRecurrentNetwork(keras_conf)\n",
    "Keras_RNN.make_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Training the Network\n",
    "\n",
    "Now run in minibatches.  The \"if\" statement means we only see the output every 50 iterations.\n",
    "The \"reset_states()\" call should reset the internal state of the model.\n",
    "Note that the reported loss is the loss (MSE) on the current batch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain,ytrain=Keras_RNN.get_training_data(Xsub_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35200"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(Xsub_scale[:,:17]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Keras_RNN.train_model(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Predicting the whole sequence\n",
    "\n",
    "This runs the network on the whole subset of data we've pulled out from 2000 to 2008.  This checks performance on both the training data,\n",
    "as well as the holdout data.  As we'll see, the performance drops precipitously once training ends.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rnn_pred=Keras_RNN.avg_predict_from_model(Xsub_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc75dd15240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=6\n",
    "plt.plot(rnn_pred[:,i],'--')\n",
    "plt.plot(Xsub_scale[:,i],label=df_tot.columns[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, the model is doing terribly.  I thought it would at least track the correct price (and get the directions wrong).\n",
    "As is, the resulting predictions are wandering far away from the actual price, even when given the correct price data.\n",
    "\n",
    "Does this make sense?  Under one point of view, these variables are all random walks.  Even if they are correlated,\n",
    "then, we can find some independent variables which are also given by random walks.  We're fitting a neural network with\n",
    "memory, and training it to fit this noise.  And when fed new noise, the results are wandering away from the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Simple Deep Network\n",
    "\n",
    "Let's try just making a really wide network.  With all inputs and times at once, and predicting all outputs at once.\n",
    "\n",
    "Making this work does require lots of reshaping inputs/outputs from 2D to 1D.\n",
    "I've put this in an OOP structure to try and maintain some hygiene due to multiple models using the same data.\n",
    "I hope I've caught all of the bugs from when this was just a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from neural_networks.KerasDeepNetwork import deep_network_confiig\n",
    "from neural_networks.KerasDeepNetwork import deep_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "deep_conf=deep_network_config()\n",
    "deep_conf.Nstocks=0\n",
    "DNN=deep_network(deep_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2210"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Netf+Nind)*deep_conf.Ntime_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#grab some data for train/validation\n",
    "X=df_tot.loc['2001':'2017'].values\n",
    "times=df_tot.loc['2001':'2017'].index.values\n",
    "#scale based solely on training window\n",
    "\n",
    "#split 3/4 as training, 1/4 as validation\n",
    "N=len(X)\n",
    "Nc=int(deep_conf.train_frac*N)\n",
    "\n",
    "\n",
    "X_train_scale, X_train_range, X_train_avg=scale_maxmin(X[:Nc,:])\n",
    "#now select\n",
    "X_train_sub,y_train,ind_x=DNN.get_training_data(X_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 161us/step - loss: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 215us/step - loss: 0.0570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 198us/step - loss: 0.0468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 188us/step - loss: 0.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 167us/step - loss: 0.0378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 163us/step - loss: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 183us/step - loss: 0.0311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 191us/step - loss: 0.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 193us/step - loss: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 165us/step - loss: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 168us/step - loss: 0.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 165us/step - loss: 0.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 187us/step - loss: 0.0248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 162us/step - loss: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 186us/step - loss: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 189us/step - loss: 0.0266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 189us/step - loss: 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 173us/step - loss: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 183us/step - loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 193us/step - loss: 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 161us/step - loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 215us/step - loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 185us/step - loss: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 170us/step - loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 188us/step - loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 204us/step - loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 162us/step - loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 158us/step - loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 207us/step - loss: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 163us/step - loss: 0.0171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 178us/step - loss: 0.0205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 235us/step - loss: 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 194us/step - loss: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 185us/step - loss: 0.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 185us/step - loss: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 184us/step - loss: 0.0218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 215us/step - loss: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 148us/step - loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 156us/step - loss: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 166us/step - loss: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 207us/step - loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 189us/step - loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 218us/step - loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 212us/step - loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 172us/step - loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 182us/step - loss: 0.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 159us/step - loss: 0.0175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 172us/step - loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 165us/step - loss: 0.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 204us/step - loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 150us/step - loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 179us/step - loss: 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 146us/step - loss: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 177us/step - loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 155us/step - loss: 0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 195us/step - loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 172us/step - loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 181us/step - loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 177us/step - loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 162us/step - loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 160us/step - loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 177us/step - loss: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 174us/step - loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 158us/step - loss: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 183us/step - loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 186us/step - loss: 0.0197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 180us/step - loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 164us/step - loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 177us/step - loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 179us/step - loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 202us/step - loss: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 164us/step - loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 184us/step - loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 156us/step - loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 182us/step - loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 223us/step - loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 174us/step - loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 178us/step - loss: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 199us/step - loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 187us/step - loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 161us/step - loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 197us/step - loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 164us/step - loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 196us/step - loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 182us/step - loss: 0.0153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 157us/step - loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 161us/step - loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 157us/step - loss: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 169us/step - loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 154us/step - loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 192us/step - loss: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 195us/step - loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 180us/step - loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "100/100 [==============================] - 0s 142us/step - loss: 0.0143\n"
     ]
    }
   ],
   "source": [
    "DNN.make_network(activ='relu')\n",
    "DNN.train_model(X_train_sub,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#now scale all of the data.lo\n",
    "logX=take_log10(X)\n",
    "Xscale=(logX-X_train_avg)/X_train_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#predict on whole range\n",
    "pred=DNN.avg_predict_from_model(Xscale[:,ind_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbaf6f4208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for k in range(Netf):\n",
    "    plt.subplot(4,2,k+1)\n",
    "    plt.plot_date(times,pred[:,k],'--',label='pred')\n",
    "    plt.plot_date(times,Xscale[:,-Netf+k],'-')#[:,ind_etf[k]])\n",
    "    plt.title(df_tot.columns[-Netf+k])\n",
    "    plt.plot_date([times[Nc]]*2,[-1,1],'k')\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So this is overfitting like crazy again! A simple linear regression would work better at this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Running on Dec-Apr inputs.\n",
    "\n",
    "Now to augment the dataset with the most recent indicators/ETFs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Linear Prediction\n",
    "\n",
    "So, let's make a linear prediction based on the last year's trend.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#df_tot.tail().iloc[:,-Netf:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Estimate a linear trend\n",
    "df_tail=df_tot.tail(n=100).iloc[:,-Netf:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#estimate mean difference.  \n",
    "df_final_inc=df_tail.diff(1).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_final=df_tail.iloc[-1].values\n",
    "df_ta=df_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1455.25    ,   147.039566,    91.540939,   120.301598,   162.012939,\n",
       "         172.077026,   136.928207])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "date=df_tail.index[-1]\n",
    "final_dates=pd.date_range(start=date,end='2017-12-31',freq='W')\n",
    "\n",
    "df_final=np.zeros((len(final_dates),7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nt = len(final_dates)\n",
    "for i in range(nt):\n",
    "    df_final[i]=df_final_val+i*df_final_inc\n",
    "\n",
    "#make a dataframe of values\n",
    "df_final2=pd.DataFrame(df_final,index=final_dates,columns=df_tail.columns)\n",
    "df_final2.to_csv('linear_etf_fit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Forecast from last timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#grab last values, up to last observation. \n",
    "X_test=df_tot.iloc[-395:-95].values\n",
    "\n",
    "logX_test=take_log10(X_test)\n",
    "X_test_scale=(logX_test-X_train_avg)/X_train_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?np.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_test_in = X_test_scale[-DNN.conf.Ntime_in:,ind_x].reshape(-1)\n",
    "#stack 2 on top to sidestep batching fuckwittery.\n",
    "#X_test_in2 = np.vstack([X_test_in,X_test_in])\n",
    "\n",
    "X_test_in2 = X_test_in.reshape((1,len(X_test_in)))\n",
    "\n",
    "ytest=DNN.model.predict(X_test_in2,batch_size=1)\n",
    "ytest=ytest.reshape((DNN.conf.Ntime_out, Netf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ytest_pred=10**(X_train_range[-7:]*ytest+X_train_avg[-7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make a date-range\n",
    "import datetime as dt\n",
    "start=dt.datetime(2017,12,16)\n",
    "end=dt.datetime(2018,4,30)\n",
    "dates=pd.date_range(start,end)\n",
    "#keep only weekdays\n",
    "dates=dates[dates.dayofweek<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_ytest=pd.DataFrame(ytest_pred[:96],index=dates,columns=df_etf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Basic Materials (IYM)  Consumer Goods (IYK)  Healthcare (IYH)  \\\n",
       "2017-12-18              68.129664             77.520866         94.858958   \n",
       "2017-12-19              68.335517             77.633922         95.228138   \n",
       "2017-12-20              68.578852             77.756150         95.188714   \n",
       "2017-12-21              68.642016             77.883060         95.413186   \n",
       "2017-12-22              68.778956             78.090868         95.981247   \n",
       "2017-12-25              69.020973             78.023959         95.818863   \n",
       "2017-12-26              68.948442             77.987383         95.707846   \n",
       "2017-12-27              68.474066             78.028232         95.890904   \n",
       "2017-12-28              68.703995             78.013034         95.945392   \n",
       "2017-12-29              68.545821             77.934206         95.828509   \n",
       "2018-01-01              68.221286             77.783429         95.756130   \n",
       "2018-01-02              68.241852             77.918786         95.972204   \n",
       "2018-01-03              68.427128             77.960280         96.235065   \n",
       "2018-01-04              68.448082             77.928707         96.529854   \n",
       "2018-01-05              68.555320             78.144419         96.677797   \n",
       "2018-01-08              68.676649             78.317888         96.823956   \n",
       "2018-01-09              68.728169             78.444803         96.740859   \n",
       "2018-01-10              68.498858             78.434096         96.704691   \n",
       "2018-01-11              68.542354             78.536096         96.781224   \n",
       "2018-01-12              68.511631             78.500977         96.637283   \n",
       "2018-01-15              68.688845             78.659303         96.736479   \n",
       "2018-01-16              68.304885             78.499273         96.391798   \n",
       "2018-01-17              68.200623             78.556744         96.611405   \n",
       "2018-01-18              68.394620             78.648889         97.011147   \n",
       "2018-01-19              68.329602             78.410276         97.000081   \n",
       "2018-01-22              68.344480             78.503507         96.904841   \n",
       "2018-01-23              68.490635             78.666702         96.961340   \n",
       "2018-01-24              68.476405             78.839908         97.126712   \n",
       "2018-01-25              68.485723             78.899783         97.003069   \n",
       "2018-01-26              68.495244             78.825119         96.813774   \n",
       "...                           ...                   ...               ...   \n",
       "2018-03-20              69.334768             80.980823         99.466885   \n",
       "2018-03-21              69.437141             80.930069         99.419999   \n",
       "2018-03-22              69.533500             81.082882         99.829189   \n",
       "2018-03-23              69.492648             81.038026         99.715993   \n",
       "2018-03-26              69.321938             80.906495         99.567883   \n",
       "2018-03-27              69.258593             80.767849         99.469361   \n",
       "2018-03-28              69.491303             80.880563         99.932658   \n",
       "2018-03-29              69.472126             80.747479         99.819037   \n",
       "2018-03-30              69.397497             80.610407         99.722902   \n",
       "2018-04-02              69.644867             80.797409         99.895086   \n",
       "2018-04-03              69.308194             80.708563         99.740433   \n",
       "2018-04-04              69.379472             80.786099         99.499245   \n",
       "2018-04-05              69.636264             80.785071         99.615831   \n",
       "2018-04-06              69.490203             80.971067         99.730971   \n",
       "2018-04-09              69.580422             81.026902         99.820031   \n",
       "2018-04-10              69.612990             81.055167         99.667319   \n",
       "2018-04-11              69.426983             80.856994         99.512997   \n",
       "2018-04-12              69.540403             81.007847         99.541018   \n",
       "2018-04-13              69.939007             81.200225         99.902329   \n",
       "2018-04-16              69.676626             80.949817         99.623845   \n",
       "2018-04-17              69.949698             81.205519        100.123497   \n",
       "2018-04-18              69.736451             81.133230        100.003876   \n",
       "2018-04-19              69.686367             81.065033         99.985909   \n",
       "2018-04-20              69.841161             81.221247        100.208213   \n",
       "2018-04-23              69.720581             81.035875         99.880567   \n",
       "2018-04-24              69.776273             80.878532         99.824528   \n",
       "2018-04-25              69.991810             81.119987        100.059620   \n",
       "2018-04-26              70.028747             81.303977        100.318431   \n",
       "2018-04-27              70.011011             81.450715        100.470687   \n",
       "2018-04-30              69.964840             81.427244        100.582665   \n",
       "\n",
       "            Market (^RUA)  Services (IYC)  Technology (IYW)  Utilities (IDU)  \n",
       "2017-12-18     990.253541       99.611751         76.162038        81.197209  \n",
       "2017-12-19     992.523037       99.965288         76.351392        81.272432  \n",
       "2017-12-20     995.157125      100.019674         76.668716        81.511623  \n",
       "2017-12-21     997.775243      100.314063         76.902495        81.844897  \n",
       "2017-12-22    1001.772687      100.823183         77.305309        82.216627  \n",
       "2017-12-25    1002.929819      100.706359         77.260056        82.292622  \n",
       "2017-12-26    1002.017495      100.792935         77.174069        82.238899  \n",
       "2017-12-27     998.907484      100.702289         76.727824        81.929056  \n",
       "2017-12-28     999.169824      100.589604         76.523612        82.068312  \n",
       "2017-12-29     997.786793      100.539033         76.231272        81.960251  \n",
       "2018-01-01     993.877373      100.414512         76.125387        81.437630  \n",
       "2018-01-02     996.502640      100.727157         76.257111        81.626031  \n",
       "2018-01-03     998.702914      100.912092         76.297813        81.680306  \n",
       "2018-01-04    1000.083084      101.266482         76.431417        81.774546  \n",
       "2018-01-05    1001.706607      101.273334         76.341472        81.818067  \n",
       "2018-01-08    1004.145522      101.493506         76.482076        82.115223  \n",
       "2018-01-09    1005.224747      101.644123         76.498049        82.178050  \n",
       "2018-01-10    1003.561519      101.479311         76.265604        82.099350  \n",
       "2018-01-11    1006.213786      101.768231         76.565345        81.912110  \n",
       "2018-01-12    1005.711602      101.691663         76.369840        81.935944  \n",
       "2018-01-15    1006.438650      101.742473         76.240770        82.207652  \n",
       "2018-01-16    1002.381936      101.298381         75.831197        81.910612  \n",
       "2018-01-17    1003.586951      101.419206         75.964465        82.107784  \n",
       "2018-01-18    1005.138005      101.407155         76.055431        82.254048  \n",
       "2018-01-19    1003.599242      101.406213         75.898474        82.116357  \n",
       "2018-01-22    1003.883329      101.300464         75.802429        82.193011  \n",
       "2018-01-23    1006.149721      101.541617         75.964231        82.545717  \n",
       "2018-01-24    1006.036126      101.774618         76.042543        82.644737  \n",
       "2018-01-25    1006.100574      101.795147         76.065710        82.701773  \n",
       "2018-01-26    1005.356490      101.723231         75.859486        82.525879  \n",
       "...                   ...             ...               ...              ...  \n",
       "2018-03-20    1027.833325      104.387066         77.254656        83.501058  \n",
       "2018-03-21    1028.489894      104.466772         77.276158        83.492753  \n",
       "2018-03-22    1029.408590      104.783831         77.413817        83.606778  \n",
       "2018-03-23    1028.569939      104.644355         77.170244        83.627102  \n",
       "2018-03-26    1024.666369      104.362004         76.703027        83.434713  \n",
       "2018-03-27    1024.191449      104.245017         76.607666        83.213781  \n",
       "2018-03-28    1026.783859      104.458742         76.882208        83.449030  \n",
       "2018-03-29    1025.948578      104.155726         76.829919        83.367981  \n",
       "2018-03-30    1025.096175      103.957571         76.661125        83.130191  \n",
       "2018-04-02    1028.552224      104.232777         76.935057        83.394148  \n",
       "2018-04-03    1026.348202      104.146217         76.728884        83.586978  \n",
       "2018-04-04    1027.386888      104.094565         76.875990        83.728092  \n",
       "2018-04-05    1029.449102      104.390591         77.096852        84.089699  \n",
       "2018-04-06    1029.603824      104.458659         77.261066        83.825469  \n",
       "2018-04-09    1031.957676      104.409554         77.416779        84.008251  \n",
       "2018-04-10    1032.550733      104.446340         77.504090        84.023655  \n",
       "2018-04-11    1030.464703      104.336092         77.260027        83.908795  \n",
       "2018-04-12    1032.670420      104.565574         77.351515        84.033204  \n",
       "2018-04-13    1036.799214      104.993373         77.749468        84.553483  \n",
       "2018-04-16    1031.935859      104.476403         77.322955        84.237383  \n",
       "2018-04-17    1036.777149      104.955747         77.630718        84.488647  \n",
       "2018-04-18    1033.583913      104.761064         77.512046        84.435957  \n",
       "2018-04-19    1033.665048      104.645870         77.620867        84.582425  \n",
       "2018-04-20    1036.406531      105.011545         77.708834        84.742921  \n",
       "2018-04-23    1032.495887      104.505982         77.287653        84.507750  \n",
       "2018-04-24    1032.820414      104.508742         77.602639        84.633628  \n",
       "2018-04-25    1036.753181      104.763120         77.898401        84.835419  \n",
       "2018-04-26    1037.862543      105.032073         77.911848        85.052736  \n",
       "2018-04-27    1038.666868      105.073581         77.989523        85.203911  \n",
       "2018-04-30    1037.681419      105.057920         78.010753        85.069331  \n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_etf3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-f3d8c2f522d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_etf3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_etf3' is not defined"
     ]
    }
   ],
   "source": [
    "df_etf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?re.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dfcol_order=['Technology (IYW)', 'Basic Materials (IYM)', 'Consumer Goods (IYK)',\n",
    "       'Services (IYC)', 'Healthcare (IYH)', 'Utilities (IDU)',\n",
    "       'Market (^RUA)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_test_fri=df_ytest[df_ytest.index.dayofweek==4]\n",
    "df_test_fri.loc[:'2018-4-6'][dfcol_order].to_csv('DNN_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb322f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "\n",
    "for i in range(7):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    plt.plot(df_ytest[etf_cols[i]],label=etf_cols[i]+'-pred')\n",
    "    plt.plot(df_etf3[etf_cols[i]],label=etf_cols[i]+'-3')\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# ALL BROKEN FROM HERE ON! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Keras Recurrent Neural Network\n",
    "\n",
    "Let's build a similar recurrent network in Keras (just using the adjusted close for now). \n",
    "\n",
    "The goal is to predict the a whole quarters worth of weekly returns on 6 sectors, denoted by $\\mathbf{y}_{t}$, based on a sequence of inputs $\\mathbf{x}_{t}$, which can be (stocks, previous values of the inputs, macroeconomic indicators ).\n",
    "\n",
    "We will use a recurrent network, which should map a whole sequence of previous inputs to another sequence of output vectors.\n",
    "\\begin{equation}\n",
    "  \\hat{y}_{t+n} = RNN(\\mathbf{x}_t,\\mathbf{x}_{t-1},\\ldots \\mathbf{x}_{t-\\tau})\n",
    "\\end{equation}\n",
    "where $\\tau$ is the maximum period we look back over, and $n$ is the number of periods we are looking forward over.\n",
    "\n",
    "Ideally, we would use all output times together to predict the outputs.\n",
    "I think a reshape is in order here?\n",
    "\n",
    "The LSTM will make a bunch of predictions for each time step (we will forecast fewer time steps than we input).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Tensorflow Recurrent Neural Network\n",
    "\n",
    "This model is just a test based purely on the stock data.\n",
    "The network uses a multi-layer RNN, with two hidden layers at input/output.  They use leaky ReLU activation.\n",
    "The model currently plays with 100 stocks from 2002-2006.\n",
    "\n",
    "This uses a model I've cobbled together in Tensorflow.\n",
    "The OO structure is borrowed from the online problem sets\n",
    "from CS224 on NLP offered in 2017 at Stanford.\n",
    "The NN is borrowed from A. Geron \"Hands on Machine Learning with Scikit-Learn and Tensorflow\", which I've found to be the best\n",
    "overall introduction, and has a good mix of background, and code.\n",
    "(There is also an associated Github account with code).\n",
    "\n",
    "The Tensorflow docs were pretty hard reading, and there seem to be lots\n",
    "of tricks that only practitioners on StackOverflow are aware of.  (But the tutorials are pretty readable.)\n",
    "\n",
    "Note network currently only predicts one timestep into the future. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from neural_networks.recurrent_network import recurrent_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Fitting RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 100) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 100) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 100) dtype=float32>))\n",
      "Tensor(\"strided_slice:0\", shape=(2, ?, 300), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#define network.\n",
    "#Note a lot of network parameters are defined in __init__ in \"recurrent_network.py\".\n",
    "#A more robust structure would pass a config dict or something like that.\n",
    "RNN=recurrent_NN(60,Nstocks,100,Nstocks,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2dc295e33583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf_models/rnn_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#Note the tiny, tiny errors.  Probably badly overfitting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Need to fix the dropout so it's only on in training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/Data-Science/PDX_DataScience/PDX_finance/recurrent_network.py\u001b[0m in \u001b[0;36mtrain_graph\u001b[0;34m(self, Xi, yi, save_name)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m#select random starting point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mt2_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnprint\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/Data-Science/PDX_DataScience/PDX_finance/recurrent_network.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, sess, inputs_batch, labels_batch)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[1;32m    197\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #20. Current MSE:0.22016216814517975\n",
      "Total Time taken:21.250980377197266\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rebuild the tensorflow graph.\n",
    "RNN.build()\n",
    "#Actually train the graph on first half of data.\n",
    "#Give all of the data to this subroutine, where it selects\n",
    "# the inputs and target data in get_random_batch\n",
    "\n",
    "RNN.train_graph(Xtrain,Xtrain,save_name='tf_models/rnn_test')\n",
    "#Note the tiny, tiny errors.  Probably badly overfitting.\n",
    "#Need to fix the dropout so it's only on in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Predict on all of the data.\n",
    "#This loads up a previous model.\n",
    "#RNN_pred=RNN.predict_all('tf_models/rnn_test',20,Xsub2,reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pred(X,pred,indx_range):\n",
    "    \"\"\"Plots a particular stock and the prediction\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.plot(X[:,indx_range])\n",
    "    plt.plot(pred[:,indx_range])\n",
    "    plt.plot([len(X)/2]*2,[-1,1],'k-')\n",
    "    plt.legend(['Actual','Forecast'])\n",
    "    plt.title('Raw')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(np.cumsum(X[:,indx_range],axis=0))\n",
    "    plt.plot(np.cumsum(pred[:,indx_range],axis=0))\n",
    "    plt.legend(['Actual','Forecast'])    \n",
    "    plt.title('Cumulative')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCiKoih+/D954ai3iCVuoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba5b7e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Could make predicted results a time series for nicer formating, and dates.\n",
    "#Plot cumulative for cases when we've also differenced.\n",
    "plot_pred(Xsub2,RNN_pred,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This RNN forecast is also WAY worse than a persistence forecast (tomorrow's price is the same as todays).\n",
    "Big question: why is the price wandering away? Even if the model is fixed (weights unchanged), surely it should take the recent past (which the model uses to forecast tomorrow's demand) into account.\n",
    "\n",
    "Note the effect of further smoothing, which suggests a clearer trend, that might be easier to model.\n",
    "That suggests the convolutional networks may be useful,\n",
    "perhaps with running averages to smooth the data.  Forecasting on a week timescale might allevative some of that too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba5c45550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's look at the differences between the predicted and actual\n",
    "#results at the end of the period.\n",
    "pred_diff=RNN_pred[-1]-Xsub2[-1]\n",
    "plt.hist(pred_diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Let's now see how much the predictions vary (across all stocks) at the end of training, 20 trading days after that,\n",
    "# and at the end of the period, a year or two out.\n",
    "\n",
    "#Note that these predictions use the data from those periods, but the model is not being updated.\n",
    "\n",
    "def plot_err_hist(target,pred,Nc):\n",
    "    '''plot_err_hist\n",
    "\n",
    "    Makes histograms of the errors between the target and prediction\n",
    "    at multiple time scales aroud the tend of the training period.\n",
    "    '''\n",
    "    \n",
    "    Nc = int(len(Xsub2)/2)\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    pred_diff=pred[Nc-20]-target[Nc-20]\n",
    "    plt.title('End of training - 20 days')\n",
    "    plt.hist(pred_diff)\n",
    "\n",
    "    plt.subplot(142)\n",
    "    pred_diff=pred[Nc]-target[Nc]\n",
    "    plt.title('End of training')\n",
    "    plt.hist(pred_diff)\n",
    "\n",
    "    plt.subplot(143)\n",
    "    pred_diff=pred[Nc+20]-target[Nc+20]\n",
    "    plt.title('End of training+20 days')\n",
    "    plt.hist(pred_diff)\n",
    "\n",
    "    plt.subplot(144)\n",
    "    pred_diff=pred[-1]-target[-1]\n",
    "    plt.hist(pred_diff)\n",
    "    plt.title('End of test')\n",
    "    plt.xlabel('Forecast Residuals')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The final graph is worst, it is also trying to predict many years ahead, based on essentially short-term info.\n",
    "Probably could describe build up of cumulative errors as a random walk?\n",
    "Would guess errors grows as sqrt(T), so the variance of this distribution grows as T.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "PDX_finance_Mar2018.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
