{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Apply Neural Networks to the Stock Market\n",
    "\n",
    "Notebook to explore limited set of NY stock exchange data over around 40 years, as part of the Portland Data Science group (Mar 2018).\n",
    "Data selected by Matt Borthwick from Yahoo! Finance.\n",
    "Working with Neural Network group: Matt, John Burt, Manny, Isil, Kenny, Jhoan, Mark C.\n",
    "\n",
    "Our goal is to predict weekly returns on 6 industry based ETFs, as well\n",
    "as aggregate market performance (such as Russel3000).  We will also\n",
    "be using some macroeconomic indicators as well.\n",
    "This notebook currently loads the data, transforms it, and applies a\n",
    "simple neural network to try predicting the next days stock prices.\n",
    "The first model was built in tensorflow (and is currently broken).  THere is a second network written in Keras.\n",
    "\n",
    "The plan is to train on this data (up to Sep 2017),\n",
    "validate on (Oct-Dec 2017), and test in final session on (Jan-Mar 2018).\n",
    "\n",
    "(For more exploratory screwing around, and other attempts at time-series see PDX_finance1)\n",
    "\n",
    "Currently Contains:\n",
    "-Colab setup\n",
    "-Loading data\n",
    "-Tensorflow RNN (currently borked at prediction stage - wrong size? No idea what changed)\n",
    "-Keras RNN  (not working yet)\n",
    "-Keras Deep network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Google Colab setup\n",
    "\n",
    "First up however, we need to install modules to load up our google drive for storage.  (Code taken from this helpful post https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
    "(Code and commands didn't look sketchy/malicious, but I didn't examine the PPA too closely either.)\n",
    "\n",
    "This code is for execution inside a Jupyter notebook on colab.google.com.\n",
    "It gives Colab access to your Google Drive in order to load/save data from within the notebook.\n",
    "Colab has most popular libraries (numpy, pandas, tensorflow, matplotlib).  I'm not sure how extensive it is.\n",
    "\n",
    "I've found opening a jupyter notebook on google drive automatically opens the Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Install modules on local machine.\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!echo 'past update'\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "!echo 'installed fuse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "print('past first command')\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Mounts google drive, and changes to that directory\n",
    "!mkdir -p drive \n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "import os\n",
    "os.chdir(\"drive\")\n",
    "\n",
    "#Should now be in the root of your google-drive, and now free to load/save existing files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Load Libraries and Data\n",
    "\n",
    "Now to load libraries, and data for all stocks, ETFs, and indicators.\n",
    "All of those will get stuck together into one total dataframe.\n",
    "(This is where I start my analysis on my home machine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# automatically reload files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_stock_data():\n",
    "\n",
    "    #Data compiled from Yahoo! Finance data by Matt Borthwick\n",
    "    df_close=pd.read_csv('data/stocks-us-adjClose.csv',index_col=0,parse_dates=True)\n",
    "    df_open=pd.read_csv('data/stocks-us-adjOpen.csv',index_col=0,parse_dates=True)\n",
    "    df_high=pd.read_csv('data/stocks-us-adjHigh.csv',index_col=0,parse_dates=True)\n",
    "    df_low=pd.read_csv('data/stocks-us-adjLow.csv',index_col=0,parse_dates=True)\n",
    "    df_vol=pd.read_csv('data/stocks-us-Volume.csv',index_col=0,parse_dates=True)\n",
    "    df_close.index.name='date'\n",
    "    df_open.index.name='date'\n",
    "    df_high.index.name='date'\n",
    "    df_low.index.name='date'\n",
    "    df_vol.index.name='date'\n",
    "\n",
    "    #Follow Leffers and rename columns.\n",
    "    df_close_new=[];\n",
    "    df_open_new=[];\n",
    "    df_low_new=[];\n",
    "    df_high_new=[];\n",
    "    df_vol_new=[];\n",
    "\n",
    "    for name in df_close.columns:\n",
    "        df_close_new.append(name+'close')\n",
    "\n",
    "    for name in df_open.columns:\n",
    "        df_open_new.append(name+'open')\n",
    "\n",
    "    for name in df_low.columns:\n",
    "        df_low_new.append(name+'low')\n",
    "\n",
    "    for name in df_high.columns:\n",
    "        df_high_new.append(name+'high')\n",
    "\n",
    "    for name in df_vol.columns:\n",
    "        df_vol_new.append(name+'vol')\n",
    "\n",
    "    df_close.columns=df_close_new\n",
    "    df_open.columns=df_open_new\n",
    "    df_low.columns=df_low_new\n",
    "    df_high.columns=df_high_new\n",
    "    df_vol.columns=df_vol_new\n",
    "\n",
    "    #join all stocks together.\n",
    "    df_stock=df_close.join(df_open,how='inner')\n",
    "    df_stock=df_stock.join(df_high,how='inner')\n",
    "    df_stock=df_stock.join(df_low,how='inner')\n",
    "    df_stock=df_stock.join(df_vol,how='inner')\n",
    "\n",
    "    return df_stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_information.csv  market.csv                   stocks-us-adjHigh.csv\r\n",
      "df_tot.pickle            sector_etfs-2-corrected.csv  stocks-us-adjLow.csv\r\n",
      "indicators_test.csv      sector_etfs.csv              stocks-us-adjOpen.csv\r\n",
      "Indicators_Test.csv      sector_ETFs.csv              \u001b[0m\u001b[01;31mstocks-us-moreData.zip\u001b[0m\r\n",
      "Indicators_Train.csv     stocks-us-adjClose.csv       stocks-us-Volume.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "#so columns match up\n",
    "print(np.sum(df_close.columns!=df_low.columns),\n",
    "np.sum(df_close.columns!=df_high.columns),\n",
    "np.sum(df_close.columns!=df_open.columns),\n",
    "np.sum(df_close.columns!=df_vol.columns))\n",
    "#and indices match up.\n",
    "print(np.sum(df_close.index!=df_low.index),\n",
    "np.sum(df_close.index!=df_high.index),\n",
    "np.sum(df_close.index!=df_open.index),\n",
    "np.sum(df_close.index!=df_vol.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_market=pd.read_csv('data/market.csv',index_col=0,parse_dates=True)\n",
    "df_rua=pd.read_csv('data/^RUA.csv',index_col=0,parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\nDate                                                                          \n2018-03-08  1616.369995  1622.140015  1612.140015  1621.239990  1621.239990   \n2018-03-09  1623.890015  1648.469971  1623.890015  1648.459961  1648.459961   \n2018-03-12  1649.469971  1654.329956  1644.829956  1647.410034  1647.410034   \n2018-03-13  1650.979980  1657.670044  1633.640015  1637.189941  1637.189941   \n2018-03-14  1638.829956  1643.849976  1625.569946  1628.189941  1628.189941   \n\n           Volume  \nDate               \n2018-03-08      0  \n2018-03-09      0  \n2018-03-12      0  \n2018-03-13      0  \n2018-03-14      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rua.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_etf=load_etfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Basic Materials (IYM)', 'Consumer Goods (IYK)', 'Healthcare (IYH)',\n       'Market (^RUA)', 'Services (IYC)', 'Technology (IYW)',\n       'Utilities (IDU)'],\n      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc582d320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efbbec5bac8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etf.plot(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "etf_cols=['Technology (IYW)', 'Basic Materials (IYM)', 'Consumer Goods (IYK)',\n",
    "       'Services (IYC)', 'Healthcare (IYH)', 'Utilities (IDU)',\n",
    "       'Market (^RUA)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def test_re(etf_cols):\n",
    "    df_tot=pd.DataFrame()\n",
    "    for etf_name in etf_cols:\n",
    "        mc=re.search(etf_re,etf_name)\n",
    "        print(mc.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IYW\n",
      "IYM\n",
      "IYK\n",
      "IYC\n",
      "IYH\n",
      "IDU\n",
      "^RUA\n"
     ]
    }
   ],
   "source": [
    "    for etf_name in etf_cols:\n",
    "        mc=re.search('\\(([A-Z\\^]+)\\)',etf_name)\n",
    "        print(mc.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_new_etfs(etf_cols):\n",
    "    df_tot=pd.DataFrame()\n",
    "    for etf_name in etf_cols:\n",
    "        #match via regex\n",
    "        mc=re.search('\\(([A-Z\\^]+)\\)',etf_name)\n",
    "        #retrieve the match\n",
    "        etf_ticker=mc.group(1)      \n",
    "        df=pd.read_csv('data/latest_etf/'+etf_ticker+'.csv', index_col=0,parse_dates=True,na_values='null')\n",
    "        df.rename(columns={'Adj Close':etf_name},inplace=True)\n",
    "        #only join based on adjusted close\n",
    "\n",
    "        #Kill missing values via linear interpolation.\n",
    "        ser=df.iloc[:,4].copy()\n",
    "        msk=np.isnan(ser.values)\n",
    "        ind=np.arange(len(ser))[msk]\n",
    "        #replace multiple NA with median.\n",
    "        ser[msk]=ser.median()\n",
    "        #for isolated values, replace by the average on either side.    \n",
    "        for i in ind:\n",
    "            ser.iloc[i]=(ser.iloc[i-1]+ser.iloc[i+1])/2\n",
    "        ser.reindex(df.index )\n",
    "        df_tot=df_tot.join(ser,how='outer')\n",
    "    return df_tot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_etf3=clean_new_etfs(etf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_etf3.to_csv('data/sector_etf_Sep17-Apr18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbe27f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=5\n",
    "plt.figure()\n",
    "plt.plot(df_etf2[etf_cols[i]],label=etf_cols[i]+'-2')\n",
    "plt.plot(df_etf3[etf_cols[i]],label=etf_cols[i]+'-3')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n2017-09-01    1465.449951\n2017-09-05    1453.699951\n2017-09-06    1457.770020\n2017-09-07    1456.829956\n2017-09-08    1455.250000\n2017-09-11    1471.199951\n2017-09-12    1476.680054\n2017-09-13    1477.709961\n2017-09-14    1476.099976\n2017-09-15    1479.280029\n2017-09-18    1482.530029\n2017-09-19    1483.800049\n2017-09-20    1485.489990\n2017-09-21    1481.260010\n2017-09-22    1482.859985\n2017-09-25    1480.030029\n2017-09-26    1480.459961\n2017-09-27    1488.369995\n2017-09-28    1490.339966\n2017-09-29    1495.430054\n2017-10-02    1502.630005\n2017-10-03    1506.010010\n2017-10-04    1507.439941\n2017-10-05    1515.310059\n2017-10-06    1513.689941\n2017-10-09    1510.489990\n2017-10-10    1513.959961\n2017-10-11    1516.290039\n2017-10-12    1514.000000\n2017-10-13    1514.890015\n                 ...     \n2018-02-23    1621.739990\n2018-02-26    1639.170044\n2018-02-27    1618.089966\n2018-02-28    1600.150024\n2018-03-01    1581.170044\n2018-03-02    1591.380005\n2018-03-05    1608.609985\n2018-03-06    1614.569946\n2018-03-07    1615.329956\n2018-03-08    1621.239990\n2018-03-09    1648.459961\n2018-03-12    1647.410034\n2018-03-13    1637.189941\n2018-03-14    1628.189941\n2018-03-15    1625.900024\n2018-03-16           null\n2018-03-19    1607.689941\n2018-03-20    1609.979980\n2018-03-21    1608.569946\n2018-03-22           null\n2018-03-23    1536.270020\n2018-03-26    1576.500000\n2018-03-27    1549.020020\n2018-03-28    1544.780029\n2018-03-29    1565.560059\n2018-04-02    1530.280029\n2018-04-03    1549.329956\n2018-04-04           null\n2018-04-05    1578.020020\n2018-04-06    1544.279297\nName: Market (^RUA), Length: 149, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etf3[etf_cols[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n2017-09-11    1471.199951\n2017-09-12    1476.680054\n2017-09-13    1477.709961\n2017-09-14    1476.099976\n2017-09-15    1479.280029\n2017-09-18    1482.530029\n2017-09-19    1483.800049\n2017-09-20    1485.489990\n2017-09-21    1481.260010\n2017-09-22    1482.859985\n2017-09-25    1480.030029\n2017-09-26    1480.459961\n2017-09-27    1488.369995\n2017-09-28    1490.339966\n2017-09-29    1495.430054\n2017-10-02    1502.630005\n2017-10-03    1506.010010\n2017-10-04    1507.439941\n2017-10-05    1515.310059\n2017-10-06    1513.689941\n2017-10-09    1510.489990\n2017-10-10    1513.959961\n2017-10-11    1516.290039\n2017-10-12    1514.000000\n2017-10-13    1514.890015\n2017-10-16    1517.150024\n2017-10-17    1517.500000\n2017-10-18    1519.130005\n2017-10-19    1519.349976\n2017-10-20    1527.189941\n                 ...     \n2017-11-03    1532.270020\n2017-11-06    1534.619995\n2017-11-07    1532.140015\n2017-11-08    1534.449951\n2017-11-09    1528.400024\n2017-11-10    1527.489990\n2017-11-13    1528.849976\n2017-11-14    1525.270020\n2017-11-15    1517.089966\n2017-11-16    1530.530029\n2017-11-17    1528.329956\n2017-11-20    1531.189941\n2017-11-21    1541.790039\n2017-11-22    1540.689941\n2017-11-24    1543.750000\n2017-11-27    1542.290039\n2017-11-28    1557.900024\n2017-11-29    1557.699951\n2017-11-30    1569.219971\n2017-12-01    1565.880005\n2017-12-04    1563.699951\n2017-12-05    1556.800049\n2017-12-06    1555.510010\n2017-12-07    1561.339966\n2017-12-08    1569.359985\n2017-12-11    1573.540039\n2017-12-12    1574.920044\n2017-12-13    1574.819946\n2017-12-14    1567.260010\n2017-12-15    1582.079956\nName: Market (^RUA), Length: 69, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etf2.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Technology (IYW)', 'Basic Materials (IYM)', 'Consumer Goods (IYK)',\n       'Services (IYC)', 'Healthcare (IYH)', 'Utilities (IDU)',\n       'Market (^RUA)'],\n      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etf = pd.read_csv('data/sector_ETFs.csv',index_col=0,parse_dates=True)\n",
    "df_etf2 = pd.read_csv('data/sector_etfs-2-corrected.csv',index_col=0,parse_dates=True)\n",
    "\n",
    "df_etf2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_etfs():\n",
    "\n",
    "    #load market/ETF data\n",
    "\n",
    "    df_etf = pd.read_csv('data/sector_ETFs.csv',index_col=0,parse_dates=True)\n",
    "    df_etf2 = pd.read_csv('data/sector_etfs-2-corrected.csv',index_col=0,parse_dates=True)\n",
    "    df_etf=df_etf.append(df_etf2)\n",
    "    \n",
    "    return df_etf\n",
    "\n",
    "\n",
    "def load_market():\n",
    "\n",
    "    df_market=pd.read_csv('data/market.csv',index_col=0,parse_dates=True)\n",
    "    df_rua=pd.read_csv('data/^RUA.csv')\n",
    "    \n",
    "\n",
    "def make_target_df(df_etf,df_market):\n",
    "    df_target=pd.DataFrame.join(df_etf,other=df_market,how='outer')\n",
    "    return df_target\n",
    "    \n",
    "def load_indicators():\n",
    "\n",
    "    # remove warnings\n",
    "    import csv\n",
    "    import warnings\n",
    "\n",
    "    ##Pieter Leffer's code for reading in indicators\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Leffers ran into errors importing the file because of non-ascii characters in the heading\n",
    "    #Here is a piece of code Leffers got from stack overflow to fix that problem.\n",
    "    df_ind=[]\n",
    "    with open('data/Indicators_Train.csv', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            df_ind.append(row)\n",
    "\n",
    "    df_ind=pd.DataFrame(df_ind)\n",
    "    df_ind.columns=df_ind.iloc[0]\n",
    "    Column_Reference=df_ind.iloc[1].copy()\n",
    "    #Drop useless rows (last row is empty)\n",
    "    df_ind.drop([0,1],axis=0,inplace=True)\n",
    "\n",
    "\n",
    "    # #Change the formatting of the variables. Datetime to the ones for dates, integers for the ones that aren't\n",
    "    for i in range(0,len(df_ind.columns)):\n",
    "        col_name=df_ind.columns[i]\n",
    "        if i % 2 == 1:\n",
    "            df_ind[col_name] = pd.to_datetime(df_ind[col_name],  format = '%m/%d/%Y',  errors='coerce')\n",
    "            print(col_name,'time')\n",
    "        else:\n",
    "            df_ind[col_name] = pd.to_numeric(df_ind[col_name], errors='ignore')\n",
    "            print(col_name,'val')\n",
    "\n",
    "    # #Reset the index because we dropped rows in the DataFrame, Using the drop command to remove the old index\n",
    "    df_ind.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # #make a time index too.\n",
    "    df_ind.index=pd.DatetimeIndex(df_ind['date'])\n",
    "\n",
    "    # #drop all NaTs\n",
    "    msk=np.isnat(df_ind.index)\n",
    "    df_ind=df_ind[~msk]\n",
    "    df_ind.drop(df_ind.columns[[0,1]],axis=1,inplace=True)\n",
    "    return df_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?df_ind.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_stocks=load_stock_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_target=load_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date time\n",
      "HOUST val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOUST_dt time\n",
      "UNRATENSA val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNRATENSA_dt time\n",
      "EMRATIO val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMRATIO_dt time\n",
      "UEMPMED "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "UEMPMED_dt time\n",
      "UMCSENT val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMCSENT_dt time\n",
      "USSLIND val\n",
      "USSLIND_dt time"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KCFSI val\n",
      "KCFSI_dt time\n",
      "IPMAN val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPMAN_dt time\n",
      "VIXCLS val\n",
      "VIXCLS_dt time\n",
      "DGS10 val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGS10_dt time\n"
     ]
    }
   ],
   "source": [
    "df_ind=load_indicators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           HOUST HOUST_dt  UNRATENSA UNRATENSA_dt  EMRATIO EMRATIO_dt  \\\n",
       "date                                                                     \n",
       "1970-01-02    NaN      NaT        NaN          NaT      NaN        NaT   \n",
       "1970-01-03    NaN      NaT        NaN          NaT      NaN        NaT   \n",
       "1970-01-04    NaN      NaT        NaN          NaT      NaN        NaT   \n",
       "1970-01-05    NaN      NaT        NaN          NaT      NaN        NaT   \n",
       "1970-01-06    NaN      NaT        NaN          NaT      NaN        NaT   \n",
       "\n",
       "0           UEMPMED UEMPMED_dt  UMCSENT UMCSENT_dt  USSLIND USSLIND_dt  KCFSI  \\\n",
       "date                                                                            \n",
       "1970-01-02      NaN        NaT      NaN        NaT      NaN        NaT    NaN   \n",
       "1970-01-03      NaN        NaT      NaN        NaT      NaN        NaT    NaN   \n",
       "1970-01-04      NaN        NaT      NaN        NaT      NaN        NaT    NaN   \n",
       "1970-01-05      NaN        NaT      NaN        NaT      NaN        NaT    NaN   \n",
       "1970-01-06      NaN        NaT      NaN        NaT      NaN        NaT    NaN   \n",
       "\n",
       "0          KCFSI_dt  IPMAN IPMAN_dt  VIXCLS VIXCLS_dt  DGS10   DGS10_dt  \n",
       "date                                                                     \n",
       "1970-01-02      NaT    NaN      NaT     NaN       NaT   7.39 1969-12-03  \n",
       "1970-01-03      NaT    NaN      NaT     NaN       NaT   7.35 1969-12-04  \n",
       "1970-01-04      NaT    NaN      NaT     NaN       NaT   7.35 1969-12-05  \n",
       "1970-01-05      NaT    NaN      NaT     NaN       NaT   7.35 1969-12-05  \n",
       "1970-01-06      NaT    NaN      NaT     NaN       NaT   7.35 1969-12-05  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#drop those time columns\n",
    "Nind=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#keep numbers of Stocks, ETFS, indicators.\n",
    "Nstocks_tot=int(df_stocks.shape[1]/5)\n",
    "Netf=7\n",
    "Nind=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make vectors of indices in total to extract together.  \n",
    "close_ind=np.arange(0,Nstocks_tot)\n",
    "open_ind=np.arange(Nstocks_tot,2*Nstocks_tot)\n",
    "high_ind=np.arange(2*Nstocks_tot,3*Nstocks_tot)\n",
    "low_ind=np.arange(3*Nstocks_tot,4*Nstocks_tot)\n",
    "vol_ind=np.arange(4*Nstocks_tot,5*Nstocks_tot)\n",
    "ind_ind=np.arange(5*Nstocks_tot,5*Nstocks_tot+Nind)\n",
    "etf_ind=np.arange(5*Nstocks_tot+Nind,5*Nstocks_tot+Nind+Netf)\n",
    "\n",
    "#make global array of indices to take logs/differences of\n",
    "#take differences for stock prices and ETF data\n",
    "diff_ind = np.append(np.arange(4*Nstocks_tot),etf_ind)\n",
    "#take logs for stock prices, volumes and ETFs.\n",
    "log_ind = np.append(np.arange(5*Nstocks_tot),etf_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HOUST', 'UNRATENSA', 'EMRATIO', 'UEMPMED', 'UMCSENT', 'USSLIND',\n",
      "       'KCFSI', 'IPMAN', 'VIXCLS', 'DGS10'],\n",
      "      dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "#append indicators to end of dataframe.\n",
    "drop_col_num=df_ind.columns.str.contains('[date]|[_dt]')\n",
    "keep_col=df_ind.columns[~drop_col_num]\n",
    "print(keep_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "join_num=np.arange(1,len(df_ind.columns),2)\n",
    "df_tot=df_stocks.join(df_ind.loc[df_stocks.index,keep_col],how='left')\n",
    "df_tot=df_tot.join(df_target,how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#dump dataframe as pickle object for ease.\n",
    "file_name='data/df_tot.pickle'\n",
    "fileObj=open(file_name,'wb')\n",
    "pickle.dump(df_tot,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'absolute' did not contain a loop with signature matching types dtype('<M8[ns]') dtype('<M8[ns]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-ebd31660df01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plots the scaled values of the economic indictors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_ind_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf_ind_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mabs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5661\u001b[0m         \u001b[0mabs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5662\u001b[0m         \"\"\"\n\u001b[0;32m-> 5663\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'absolute' did not contain a loop with signature matching types dtype('<M8[ns]') dtype('<M8[ns]')"
     ]
    }
   ],
   "source": [
    "#Plots the scaled values of the economic indictors.\n",
    "sl=slice(1,-2,2)\n",
    "df_ind_scale=df_ind.iloc[:,sl].abs().max()\n",
    "cutoff=int(len(df_ind)/2)\n",
    "plt.plot(df_ind.iloc[cutoff:,sl]/df_ind_scale)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Looking at the number of NA values (summed across columns) suggests that\n",
    "there are missing values in these stocks.\n",
    "\n",
    "Could set all NA to zero, then apply linear interpolation to handle isolated\n",
    "missing days.  Let's check the pattern of missing days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29b53cba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot pattern of NA values.  Weird stripes?\n",
    "plt.figure(figsize=(10,6))\n",
    "col=df_close.columns[0:]\n",
    "plt.imshow(np.isnan(df_vol.loc['2000':,col]),aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, some stopped stocks, and one out of place one where "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Data Transformation\n",
    "\n",
    "For the initial testing, I'm just building a model based on the 100 oldest stocks (or whichever come first), and looking at 2002-2006.\n",
    "Why then?  Because it looks relatively well behaved.\n",
    "The model is trained on the first half of the data, and we then run the\n",
    "network on the whole data set.\n",
    "\n",
    "I'm currently just taking the base-10 log of the data, and scaling each\n",
    "stock to lie with [-1,1].  I found differencing the data lead to\n",
    "pretty crappy results (then again, these are also pretty crap results).\n",
    "\n",
    "So there's some choices to be played with here:\n",
    "- scaling: variance vs max/min\n",
    "- differencing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Nstocks=300\n",
    "Xsub=df_tot['2000':'2006'].iloc[:,:Nstocks].values\n",
    "\n",
    "def scale_clean_data(X):\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    X[np.isnan(X)]=0\n",
    "    #take differences of logs. (shift zero to avoid NANs)\n",
    "    #Xsub2 = np.diff(np.log10(Xsub+1E-12),axis=0)\n",
    "    X = np.log10(Xsub+1E-16)\n",
    "\n",
    "    X_max = np.max(X,axis=0)\n",
    "    X_min = np.min(X,axis=0)\n",
    "\n",
    "    #Choice of scaling here: max/min vs variance?\n",
    "    #I think variance makes more sense if differencing.\n",
    "    rng = 0.5*(X_max-X_min)\n",
    "    avg = 0.5*(X_max+X_min)\n",
    "    Xscaled= (X-avg)/rng\n",
    "    return Xscaled,rng,avg\n",
    "\n",
    "Xsub2,rng,avg=scale_clean_data(Xsub)\n",
    "\n",
    "#split 3/4 as training, 1/4 as test\n",
    "N=len(Xsub2)\n",
    "Nc=int(3*N/4)\n",
    "#make training/test splits\n",
    "Xtrain = Xsub2[:Nc]\n",
    "ytrain = Xsub2[1:Nc+1] #tomorrow's return.\n",
    "\n",
    "Xtest=Xsub2[Nc:-1]\n",
    "ytest=Xsub2[Nc+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def take_log10(X):\n",
    "    \"\"\"take_log10(X)\n",
    "    Takes base10-log of X.  Sets NaN to zero, and shifts zero values by 1E-16.\n",
    "    \"\"\"\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    y=X.copy()\n",
    "    y[np.isnan(y)]=0    \n",
    "    #take logs. (shift zero to avoid NANs)\n",
    "    y[:,log_ind] = np.log10(y[:,log_ind]+1E-16)\n",
    "    return y\n",
    "\n",
    "def scale_maxmin(X):\n",
    "    \"\"\"scale_maxmin\n",
    "\n",
    "    Scales each price column by taking log, and max/min scaling.\n",
    "    Takes log of open/high/low/volumes/etf.\n",
    "    Does not take log of indicators.\n",
    "    Max-min scales all of them.\n",
    "    Only take the log for the stock/etf data.\n",
    "    \"\"\"\n",
    "    X=take_log10(X)\n",
    "    X_max = np.nanmax(X,axis=0)\n",
    "    X_min = np.nanmin(X,axis=0)\n",
    "    #compute middle and differences of the max/min.\n",
    "    avg = 0.5*(X_max+X_min)\n",
    "    rng = 0.5*(X_max-X_min)\n",
    "    #scale to [-1,+1]\n",
    "    Xscaled= (X-avg)/rng\n",
    "    return Xscaled,rng,avg\n",
    "\n",
    "def rescale_maxmin(Xscaled,avg,rng):\n",
    "    \"\"\"rescale_maxmin\n",
    "\n",
    "    Undoes log-max/min scaling. \n",
    "    First undoes max/min scaling.  \n",
    "    Then exponentiates varaibles which had log taken.\n",
    "    \"\"\"\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    X= avg + rng*Xscaled\n",
    "    #take logs. (shift zero to avoid NANs)\n",
    "    X[:,log_ind] = 10**X[:,log_ind]\n",
    "    return X\n",
    "\n",
    "def scale_diff_var(X):\n",
    "    \"\"\"scale_diff_var\n",
    "    Scales each column by taking log, then differencing.\n",
    "    Then scales to have zero mean, and unit standard deviation..\n",
    "    Only take the log for the stock/etf data.\n",
    "    \"\"\"\n",
    "    X=take_log10(X)\n",
    "    #take differences logs. (shift zero to avoid NANs)    \n",
    "    X[:,diff_ind] = np.diff(X[:,diff_ind],axis=0)\n",
    "    X_std = np.nanstd(X,axis=0)\n",
    "    X_mean = np.nanmean(X,axis=0)\n",
    "    Xscaled= (X-X_mean)/X_std\n",
    "    return Xscaled,X_mean,X_std\n",
    "\n",
    "def rescale_diffvar(Xscaled,mu,sd,x0):\n",
    "    \"\"\"rescale_maxmin\n",
    "\n",
    "    Undoes log-max/min scaling. \n",
    "    Takes log of open/high/low/volumes/etf.\n",
    "    Does not take log of indicators.\n",
    "    Max-min scales all of them.\n",
    "    Only take the log for the stock/etf data.\n",
    "    \"\"\"\n",
    "    #set missing values to zero.  (to avoid issues in network with NaNs)\n",
    "    X= mu + sd*Xscaled\n",
    "    X= np.insert(X,0,x0,axis=0)\n",
    "    X[:,diff_ind] = np.cumsum(X[:,diff_ind],axis=0)\n",
    "    #take logs. (shift zero to avoid NANs)\n",
    "    X[:,log_ind] = 10**X[:,log_ind]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2986da1a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check scaling\n",
    "plt.figure()\n",
    "plt.plot(Xtrain[:,0:5])\n",
    "plt.plot(ytrain[:,0:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "This model is just a test based purely on the stock data.\n",
    "The network uses a multi-layer RNN, with two hidden layers at input/output.  They use leaky ReLU activation.\n",
    "The model currently plays with 100 stocks from 2002-2006.\n",
    "\n",
    "This uses a model I've cobbled together in Tensorflow.\n",
    "The OO structure is borrowed from the online problem sets\n",
    "from CS224 on NLP offered in 2017 at Stanford.\n",
    "The NN is borrowed from A. Geron \"Hands on Machine Learning with Scikit-Learn and Tensorflow\", which I've found to be the best\n",
    "overall introduction, and has a good mix of background, and code.\n",
    "(There is also an associated Github account with code).\n",
    "\n",
    "The Tensorflow docs were pretty hard reading, and there seem to be lots\n",
    "of tricks that only practitioners on StackOverflow are aware of.  (But the tutorials are pretty readable.)\n",
    "\n",
    "Note network currently only predicts one timestep into the future. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from neural_networks.recurrent_network import recurrent_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Fitting RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 100) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 100) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 100) dtype=float32>))\n",
      "Tensor(\"strided_slice:0\", shape=(2, ?, 300), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#define network.\n",
    "#Note a lot of network parameters are defined in __init__ in \"recurrent_network.py\".\n",
    "#A more robust structure would pass a config dict or something like that.\n",
    "RNN=recurrent_NN(60,Nstocks,100,Nstocks,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #20. Current MSE:0.22016216814517975\n",
      "Total Time taken:21.250980377197266\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2dc295e33583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf_models/rnn_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#Note the tiny, tiny errors.  Probably badly overfitting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Need to fix the dropout so it's only on in training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/Data-Science/PDX_DataScience/PDX_finance/recurrent_network.py\u001b[0m in \u001b[0;36mtrain_graph\u001b[0;34m(self, Xi, yi, save_name)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m#select random starting point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mt2_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnprint\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/Data-Science/PDX_DataScience/PDX_finance/recurrent_network.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, sess, inputs_batch, labels_batch)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[1;32m    197\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Rebuild the tensorflow graph.\n",
    "RNN.build()\n",
    "#Actually train the graph on first half of data.\n",
    "#Give all of the data to this subroutine, where it selects\n",
    "# the inputs and target data in get_random_batch\n",
    "\n",
    "RNN.train_graph(Xtrain,Xtrain,save_name='tf_models/rnn_test')\n",
    "#Note the tiny, tiny errors.  Probably badly overfitting.\n",
    "#Need to fix the dropout so it's only on in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Predict on all of the data.\n",
    "#This loads up a previous model.\n",
    "#RNN_pred=RNN.predict_all('tf_models/rnn_test',20,Xsub2,reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pred(X,pred,indx_range):\n",
    "    \"\"\"Plots a particular stock and the prediction\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.plot(X[:,indx_range])\n",
    "    plt.plot(pred[:,indx_range])\n",
    "    plt.plot([len(X)/2]*2,[-1,1],'k-')\n",
    "    plt.legend(['Actual','Forecast'])\n",
    "    plt.title('Raw')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(np.cumsum(X[:,indx_range],axis=0))\n",
    "    plt.plot(np.cumsum(pred[:,indx_range],axis=0))\n",
    "    plt.legend(['Actual','Forecast'])    \n",
    "    plt.title('Cumulative')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCiKoih+/D954ai3iCVuoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba5b7e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Could make predicted results a time series for nicer formating, and dates.\n",
    "#Plot cumulative for cases when we've also differenced.\n",
    "plot_pred(Xsub2,RNN_pred,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This RNN forecast is also WAY worse than a persistence forecast (tomorrow's price is the same as todays).\n",
    "Big question: why is the price wandering away? Even if the model is fixed (weights unchanged), surely it should take the recent past (which the model uses to forecast tomorrow's demand) into account.\n",
    "\n",
    "Note the effect of further smoothing, which suggests a clearer trend, that might be easier to model.\n",
    "That suggests the convolutional networks may be useful,\n",
    "perhaps with running averages to smooth the data.  Forecasting on a week timescale might allevative some of that too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba5c45550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's look at the differences between the predicted and actual\n",
    "#results at the end of the period.\n",
    "pred_diff=RNN_pred[-1]-Xsub2[-1]\n",
    "plt.hist(pred_diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.1433746024133806, 1.0660086500156463)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(pred_diff),np.std(pred_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Let's now see how much the predictions vary (across all stocks) at the end of training, 20 trading days after that,\n",
    "# and at the end of the period, a year or two out.\n",
    "\n",
    "#Note that these predictions use the data from those periods, but the model is not being updated.\n",
    "\n",
    "def plot_err_hist(target,pred,Nc):\n",
    "    '''plot_err_hist\n",
    "\n",
    "    Makes histograms of the errors between the target and prediction\n",
    "    at multiple time scales aroud the tend of the training period.\n",
    "    '''\n",
    "    \n",
    "    Nc = int(len(Xsub2)/2)\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    pred_diff=pred[Nc-20]-target[Nc-20]\n",
    "    plt.title('End of training - 20 days')\n",
    "    plt.hist(pred_diff)\n",
    "\n",
    "    plt.subplot(142)\n",
    "    pred_diff=pred[Nc]-target[Nc]\n",
    "    plt.title('End of training')\n",
    "    plt.hist(pred_diff)\n",
    "\n",
    "    plt.subplot(143)\n",
    "    pred_diff=pred[Nc+20]-target[Nc+20]\n",
    "    plt.title('End of training+20 days')\n",
    "    plt.hist(pred_diff)\n",
    "\n",
    "    plt.subplot(144)\n",
    "    pred_diff=pred[-1]-target[-1]\n",
    "    plt.hist(pred_diff)\n",
    "    plt.title('End of test')\n",
    "    plt.xlabel('Forecast Residuals')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The final graph is worst, it is also trying to predict many years ahead, based on essentially short-term info.\n",
    "Probably could describe build up of cumulative errors as a random walk?\n",
    "Would guess errors grows as sqrt(T), so the variance of this distribution grows as T.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Keras Recurrent Neural Network\n",
    "\n",
    "Let's build a similar recurrent network in Keras (just using the adjusted close for now). \n",
    "\n",
    "The goal is to predict the a whole quarters worth of weekly returns on 6 sectors, denoted by $\\mathbf{y}_{t}$, based on a sequence of inputs $\\mathbf{x}_{t}$, which can be (stocks, previous values of the inputs, macroeconomic indicators ).\n",
    "\n",
    "We will use a recurrent network, which should map a whole sequence of previous inputs to another sequence of output vectors.\n",
    "\\begin{equation}\n",
    "  \\hat{y}_{t+n} = RNN(\\mathbf{x}_t,\\mathbf{x}_{t-1},\\ldots \\mathbf{x}_{t-\\tau})\n",
    "\\end{equation}\n",
    "where $\\tau$ is the maximum period we look back over, and $n$ is the number of periods we are looking forward over.\n",
    "\n",
    "Ideally, we would use all output times together to predict the outputs.\n",
    "I think a reshape is in order here?\n",
    "\n",
    "The LSTM will make a bunch of predictions for each time step (we will forecast fewer time steps than we input).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Borrowing some from Keras docs, and \"https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\"\n",
    "import keras  \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, RNN, LSTM, StackedRNNCells, Reshape, Dropout\n",
    "from keras.losses import mean_squared_error, mean_absolute_error\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc3207ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(Xsub_scale[:,-Netf:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Xsub=df_tot.loc['2000':'2005'].values\n",
    "# method='maxmin'\n",
    "# if (method=='maxmin'):\n",
    "#    Xsub_scale,Xrng,Xavg=scale_maxmin(Xsub)\n",
    "# elif (method=='differencing'):\n",
    "#     Xsub_scale,Xrng,Xavg=scale_diff_var(Xsub)\n",
    "# else:\n",
    "\n",
    "\n",
    "# #split 3/4 as training, 1/4 as validation\n",
    "# N=len(Xsub_scale)\n",
    "# Nc=int(3*N/4)\n",
    "\n",
    "# #select out desired range of columns for training (stocks, etf, ind)\n",
    "# N0=Nstocks\n",
    "# ind_stock=np.arange(Nstocks)\n",
    "# #pull out ETFS\n",
    "# N0=Nstocks_tot\n",
    "# N1=N0+Netf\n",
    "# ind_etf=np.arange(N0,N1)\n",
    "# #pull out indicators\n",
    "# N0=Nstocks_tot+Netf\n",
    "# N1=N0+Nind\n",
    "# ind_ind=np.arange(N0, N1)\n",
    "# #combine out values to use in \n",
    "# ind_xsub=np.append(ind_stock,ind_etf)\n",
    "# ind_xsub=np.append(ind_xsub,ind_ind)\n",
    "\n",
    "# #make training/test splits\n",
    "# #train on stock, indicators and ETFs.\n",
    "# Xtrain = Xsub_scale[:Nc,ind_x]\n",
    "# ytrain= Xsub_scale[:Nc,ind_etf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I had hoped Keras would automatically take care of random temporal batching like this, but unfortunately it does not.\n",
    "So, this routine which randomly selects a batch of indices to start fitting at.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#note: this relies on looking up global parameters (blech)\n",
    "def get_rnn_batch(X,y):\n",
    "    \"\"\"get_rnn_batch\n",
    "    Returns a randomly selected batch of input/output sequences.\n",
    "    Inputs are all stocks, ETFs and indicators\n",
    "    Outputs are just future ETFs from input sequence endpoint.\n",
    "    \"\"\"\n",
    "    #starting indices\n",
    "    ind=np.arange(len(X[:,0])-Ntime_in-Ntime_out)\n",
    "    rand_ind=np.random.choice(ind,Nbatch,replace=False)\n",
    "    Xb=np.zeros((Nbatch,Ntime_in, Ninput))\n",
    "    yb=np.zeros((Nbatch,Ntime_out,Noutput))\n",
    "    #now populate table (couldn't see nice way to vectorize this assignment, mabe via overloading)\n",
    "    for i in range(Nbatch):\n",
    "        t0=rand_ind[i]\n",
    "        t1=t0+Ntime_in\n",
    "        t2=t1+Ntime_out\n",
    "        #input all past parameters\n",
    "        Xb[i]=X[t0:t1]\n",
    "        #target future ETFs\n",
    "        yb[i]=y[t1:t2]\n",
    "    return Xb,yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Making the Network\n",
    "\n",
    "The following makes a 4 layer network - a dense layer at input with linear activation to reduce dimension,\n",
    "followed by two recurrent layers (using a LSTM for longer memory),\n",
    "and a final dense layer to map from the hidden units to the final outputs.\n",
    "The LSTMs can use \"leaky ReLU\" activation, which are suited to long sequences since the gradients dont explode, or go to zero.\n",
    "The output sequences are then flattened, before being put through\n",
    "a final linear layer to add together the results.\n",
    "(In a fancy version this could be a CNN?)\n",
    "The final result is reshaped again to output a batch of sequences.\n",
    "\n",
    "The Adam optimizer is basically a fancy version of gradient descent (with a momentum, scaling based on previous updates, and learning rate scheduling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.Nstocks=100\n",
    "        self.Nfeatures=5\n",
    "        #number of times in/out.\n",
    "        self.Ntime_in=130\n",
    "        self.Ntime_out=65\n",
    "        #total linear input/outputs\n",
    "        self.Ninput=(self.Nstocks*self.Nfeatures+Netf+Nind)\n",
    "        self.Noutput=Netf\n",
    "        #network parameters\n",
    "        self.Nhidden=100\n",
    "        self.Nlayers=2\n",
    "        self.dropout_frac=0.5\n",
    "        self.Nepoch=1000\n",
    "        self.Nbatch=100\n",
    "        self.Nprint=50\n",
    "        self.train_frac=0.75\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from neural_networks.KerasRecurrentNetwork import KerasRecurrentNetwork\n",
    "\n",
    "\n",
    "# def predict_from_model(model,X):\n",
    "#     #Predict on whole of this subset (both \"training\" and \"testing\")\n",
    "#     Nf = len(X)-Ntime_in-Ntime_out\n",
    "#     ypred_tot=np.zeros((Nf,Noutput))\n",
    "#     yavg = np.zeros(Nf)\n",
    "#     i0=0\n",
    "#     i1=i0+Nbatch\n",
    "#     #split whole time sequence into sequential batches.\n",
    "#     while (i1 < Nf):\n",
    "#         X0=np.zeros((Nbatch,Ntime_in,Ninput))\n",
    "#         for i in range(Nbatch):\n",
    "#             X0[i]=X[i0+i:i0+i+Ntime]\n",
    "#         ypred=model.predict(X0,batch_size=Nbatch)\n",
    "#         #now march along batch, add up predictions.    \n",
    "#         for i in range(Nbatch):\n",
    "#             ypred_tot[Ntime_in+i0:Ntime_in+i0+Ntime_out]+=ypred[i]\n",
    "#             yavg[Ntime_in+i0:Ntime_in+i0+Ntime_out]+=1\n",
    "#         model.reset_states()    \n",
    "#         i0=i1\n",
    "#         i1+=Nbatch\n",
    "#     #predict on the remainder\n",
    "#     Nrem=Nf-i0\n",
    "#     X0=np.zeros((Nrem,Ntime,Ninput))\n",
    "#     for i in range(Nrem):\n",
    "#         X0[i]=X[i0+i:i0+i+Ntime]\n",
    "#     ypred=model.predict(X0,batch_size=Nrem)\n",
    "#     #now march along batch, add up predictions.    \n",
    "#     for i in range(Nrem):\n",
    "#         ypred_tot[Ntime_in+i0:Ntime_in+i0+Ntime_out]+=ypred[i]\n",
    "#         yavg[Ntime_in+i0:Ntime_in+i0+Ntime_out]+=1\n",
    "        \n",
    "#     ypred_tot=ypred_tot/yavg    \n",
    "   \n",
    "#     return ypred_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "keras_conf=Config()\n",
    "Keras_RNN=KerasRecurrentNetwork(keras_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make network\n",
    "k_RNN=Keras_RNN.make_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Training the Network\n",
    "\n",
    "Now run in minibatches.  The \"if\" statement means we only see the output every 50 iterations.\n",
    "The \"reset_states()\" call should reset the internal state of the model.\n",
    "Note that the reported loss is the loss (MSE) on the current batch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rnn_model=make_deep_RNN(activ='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#rnn_model=train_model(rnn_model,Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#ypred=predict_from_model(model,Xsub_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Predicting the whole sequence\n",
    "\n",
    "This runs the network on the whole subset of data we've pulled out from 2000 to 2008.  This checks performance on both the training data,\n",
    "as well as the holdout data.  As we'll see, the performance drops precipitously once training ends.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_predictions(X,ytarget,ypred,Nplot_start,skip):\n",
    "    Nplot_end=Nplot_start+skip\n",
    "    plt.figure(figsize=(20,12))\n",
    "    legend_list=[]\n",
    "\n",
    "    Ntime,Nstocks=X.shape\n",
    "    #plot prediction    \n",
    "    for i in range(Nplot_start,Nplot_end):\n",
    "        j = i-Nstocks;\n",
    "        if (method=='differencing' or method=='roll_avg_diff'):\n",
    "            plt.plot(np.cumsum(ypred[:,i],axis=0),'--')\n",
    "        else:\n",
    "            plt.plot(ypred[:,i],'--')\n",
    "        if (np.abs(j)>7):\n",
    "                legend_list.append(df_tot.columns[i]+'-pred')\n",
    "        else:\n",
    "                legend_list.append(df_tot.columns[j]+'-pred')\n",
    "               \n",
    "    #plot actual    \n",
    "    for i in range(Nplot_start,Nplot_end):\n",
    "        j = i-Nstocks;    \n",
    "        if (method=='differencing' or method=='roll_avg_diff'):\n",
    "            plt.plot(np.cumsum(ytarget[:,i],axis=0),'--')\n",
    "        else:\n",
    "            plt.plot(ytarget[:,i],'-.')\n",
    "\n",
    "        if (np.abs(j)>7):\n",
    "                legend_list.append(df_tot.columns[i]+'-target')\n",
    "        else:\n",
    "                legend_list.append(df_tot.columns[j]+'-target')\n",
    "    plt.plot([Nc,Nc],[-1,1],'k')    \n",
    "    plt.legend(legend_list,bbox_to_anchor=(1,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ypred=predict_from_model(model,Xsub_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2505, 307), (2515, 307))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred.shape,ytot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb85e2a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(Xsub_scale,ytot,ypred,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f417ccee518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot errors\n",
    "plt.figure()\n",
    "Nplot_start=0\n",
    "Nplot_end=2\n",
    "legend_list=[];\n",
    "for i in range(Nplot_start,Nplot_end):\n",
    "    plt.plot(ypred[:,i]-ytot[Nahead:-Nahead,i])\n",
    "    legend_list.append(df_target.columns[i])\n",
    "plt.title('Model Errors over time')\n",
    "plt.legend(legend_list,bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_err_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-5431582482e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_err_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXsub_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_err_hist' is not defined"
     ]
    }
   ],
   "source": [
    "plot_err_hist(Xsub_scale,Nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, the model is doing terribly.  I thought it would at least track the correct price (and get the directions wrong).\n",
    "As is, the resulting predictions are wandering far away from the actual price, even when given the correct price data.\n",
    "\n",
    "Does this make sense?  Under one point of view, these variables are all random walks.  Even if they are correlated,\n",
    "then, we can find some independent variables which are also given by random walks.  We're fitting a neural network with\n",
    "memory, and training it to fit this noise.  And when fed new noise, the results are wandering away from the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Simple Deep Network\n",
    "\n",
    "Let's try just making a really wide network.  With all inputs and times at once, and predicting all outputs at once.\n",
    "\n",
    "Making this work does require lots of reshaping inputs/outputs from 2D to 1D.\n",
    "I've put this in an OOP structure to try and maintain some hygiene due to multiple models using the same data.\n",
    "I hope I've caught all of the bugs from when this was just a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make a Keras model simple wide, with dense input/outputs.\n",
    "class deep_network(object):\n",
    "    Netf=7\n",
    "    Netf=10\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Wrapper for Keras Network.  Uses multiple layers.\n",
    "        Reshapes values from multiple times to a single vector.\n",
    "        Network outputs single vector of ETFs as multiple times.\n",
    "        \"\"\"\n",
    "        self.Nstocks=100\n",
    "        self.Nfeatures=5\n",
    "        #number of times in/out.\n",
    "        self.Ntime_in=130\n",
    "        self.Ntime_out=65\n",
    "        #total linear input/outputs\n",
    "        self.Ninput=(self.Nstocks*self.Nfeatures+Netf+Nind) *self.Ntime_in\n",
    "        self.Noutput=Netf*self.Ntime_out\n",
    "        #network parameters\n",
    "        self.Nhidden=100\n",
    "        self.Nlayers=2\n",
    "        self.dropout_frac=0.5\n",
    "        self.Nepoch=1000\n",
    "        self.Nbatch=100\n",
    "        self.Nprint=50\n",
    "        self.train_frac=0.75\n",
    "        keras.backend.clear_session()\n",
    "        self.model=Sequential()\n",
    "\n",
    "    def make_network(self,activ='relu'):\n",
    "        \"\"\"make_network\n",
    "        Makes a deep multilayer network with dropout.\n",
    "        Relies on flattened arrays in time as input and output.\n",
    "        So inputs will use something like X.reshape(-1).\n",
    "        And outputs will also need reshape back to form (Ntime_out,Nout)\n",
    "        \"\"\"\n",
    "        self.model.add(Dense(units=self.Nhidden, activation='linear', input_shape=(self.Ninput,))) #linear mapping at input\n",
    "        if (activ=='relu'):\n",
    "            act = keras.layers.advanced_activations.LeakyReLU( alpha=0.1)               \n",
    "            for n in range(self.Nlayers):\n",
    "                self.model.add(Dropout(rate=self.dropout_frac, noise_shape=(self.Nbatch,self.Nhidden))) \n",
    "                self.model.add(Dense(units=self.Nhidden,activation='linear'))\n",
    "                #add extra activation layer afterwards\n",
    "                self.model.add(act)\n",
    "        else:\n",
    "            for n in range(self.Nlayers):\n",
    "                self.model.add(Dropout(rate=self.dropout_frac, noise_shape=(self.Nbatch,self.Nhidden))) \n",
    "                self.model.add(Dense(units=self.Nhidden,activation=activ))\n",
    "\n",
    "        #final linear mapping at output\n",
    "        self.model.add(Dense(units=self.Noutput,activation='linear',input_shape=(self.Nhidden,))) #output layer\n",
    "        self.model.compile(optimizer='adam',loss=mean_squared_error)\n",
    "\n",
    "    def get_training_data(self,X):\n",
    "        \"\"\"get_training_data\n",
    "        Selects out a subset of the training data.\n",
    "        Requires monkey around with column indices as input data is of form:\n",
    "        [ ...stocks..., ETFS, Indicators ]\n",
    "        Those last two are static, and known.\n",
    "        Picks out a fraction of the input data and trains the rest on that. \n",
    "        \"\"\"\n",
    "        #select out desired range of columns for training (stocks, etf, ind)\n",
    "\n",
    "        indx0=np.arange(self.Nstocks)\n",
    "        Nrow,Ncol=X.shape\n",
    "        ind_x=indx0.copy()\n",
    "        for i in range(self.Nfeatures-1):\n",
    "            ind_x=np.append(i*Nstocks_tot+indx0,ind_x)\n",
    "        ind_x=np.append(np.arange(Ncol-Nind-Netf,Ncol),ind_x)\n",
    "        ind_etf=np.arange(Ncol-Netf,Ncol)\n",
    "\n",
    "        #make training/test splits\n",
    "        #train on stock, indicators and ETFs.\n",
    "        Xtrain = X[:Nc,ind_x]\n",
    "        ytrain = X[:Nc,ind_etf]\n",
    "        return Xtrain,ytrain,ind_x\n",
    "        \n",
    "    def get_batch(self,X,y):\n",
    "        \"\"\"get_batch\n",
    "        Returns a randomly selected batch of input/output sequences.\n",
    "        Inputs are all stocks, ETFs and indicators\n",
    "        Outputs are just future ETFs from input sequence endpoint.\n",
    "        \"\"\"\n",
    "        #starting indices\n",
    "        ind=np.arange(len(X[:,0])-self.Ntime_in-self.Ntime_out)\n",
    "        rand_ind=np.random.choice(ind,self.Nbatch,replace=False)\n",
    "        Xb=np.zeros((self.Nbatch,self.Ninput))\n",
    "        yb=np.zeros((self.Nbatch,self.Noutput))\n",
    "        #now populate table (couldn't see nice way to vectorize this assignment, mabe via overloading)\n",
    "        for i in range(self.Nbatch):\n",
    "            t0=rand_ind[i]\n",
    "            t1=t0+self.Ntime_in\n",
    "            t2=t1+self.Ntime_out\n",
    "            #input all past parameters\n",
    "            Xb[i]=X[t0:t1].reshape(-1)\n",
    "            #target future ETFs\n",
    "            yb[i]=y[t1:t2].reshape(-1)\n",
    "        return Xb,yb,rand_ind\n",
    "\n",
    "    def train_model(self,Xtrain,ytrain):\n",
    "        \"\"\"train_model\n",
    "        Grabs random sub-batches of data, then trains.\n",
    "        Uses two different calls to suppress output.\n",
    "        \"\"\"\n",
    "        for i in range(self.Nepoch+1):\n",
    "            #Keras assumes you have a list of X,y pairs for its sampling.\n",
    "            #Would be memory intensive to set up a whole list for this data.\n",
    "            #So wrote my own batching.\n",
    "            Xb,yb,_=self.get_batch(Xtrain,ytrain)\n",
    "            if (i)%self.Nprint==0:\n",
    "                self.model.fit(Xb,yb, epochs=1, batch_size=self.Nbatch, verbose=1)\n",
    "            else:\n",
    "                self.model.fit(Xb,yb, epochs=1, batch_size=self.Nbatch, verbose=0)\n",
    "            self.model.reset_states()\n",
    "\n",
    "    def avg_predict_from_model(self,X):\n",
    "        \"\"\"avg_predict_from_model\n",
    "\n",
    "        Currently runs all prediction on the given input X.  \n",
    "        Also currently takes a naive AVERAGE(!) over all of the output predictions. \n",
    "        \"\"\"\n",
    "        #Predict on whole of this subset (both \"training\" and \"testing\")\n",
    "\n",
    "        #compute total number of predictions to be made. \n",
    "        Nf = len(X) - self.Ntime_in - self.Ntime_out\n",
    "        ypred_tot=np.zeros((len(X),Netf))\n",
    "        yavg = np.zeros((len(X),1))\n",
    "        i0=0\n",
    "        i1=i0+self.Nbatch\n",
    "        #split whole time sequence into sequential batches.\n",
    "        while (i1 < Nf):\n",
    "            X0=np.zeros((self.Nbatch,self.Ninput))\n",
    "            for i in range(self.Nbatch):\n",
    "                t0=i0+i\n",
    "                t1=t0+self.Ntime_in\n",
    "                X0[i]=X[t0:t1].reshape(-1)\n",
    "            ypred=self.model.predict(X0,batch_size=self.Nbatch)\n",
    "            #now march along batch, add up predictions.    \n",
    "            for i in range(self.Nbatch):\n",
    "                t0=self.Ntime_in+i0+i\n",
    "                t1=t0+self.Ntime_out\n",
    "                yi=ypred[i].reshape( (self.Ntime_out, Netf))\n",
    "                ypred_tot[t0:t1]+= yi\n",
    "                yavg[t0:t1]+=1\n",
    "            self.model.reset_states()    \n",
    "            i0=i1\n",
    "            i1+=self.Nbatch\n",
    "        #predict on the remainder\n",
    "        Nrem=Nf-i0\n",
    "        X0=np.zeros((Nrem,self.Ninput))\n",
    "        for i in range(Nrem):\n",
    "            t0=i0+i\n",
    "            t1=t0+self.Ntime_in\n",
    "            X0[i]=X[t0:t1].reshape(-1)\n",
    "        ypred=self.model.predict(X0,batch_size=Nrem)\n",
    "        #now march along batch, add up predictions.    \n",
    "        for i in range(Nrem):\n",
    "            t0=self.Ntime_in+i0+i\n",
    "            t1=t0+self.Ntime_out\n",
    "            yi=ypred[i].reshape((self.Ntime_out,Netf))\n",
    "            ypred_tot[t0:t1]+= yi\n",
    "            yavg[t0:t1]+=1\n",
    "\n",
    "        ypred_tot=ypred_tot/yavg    \n",
    "\n",
    "        return ypred_tot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "DNN=deep_network()\n",
    "#grab some data for train/validation\n",
    "X=df_tot.loc['2001':'2016'].values\n",
    "times=df_tot.loc['2001':'2016'].index.values\n",
    "\n",
    "#split 3/4 as training, 1/4 as validation\n",
    "N=len(X)\n",
    "Nc=int(DNN.train_frac*N)\n",
    "#scale based solely on training window\n",
    "X_train_scale, X_train_range, X_train_avg=scale_maxmin(X[:Nc,:])\n",
    "#now select\n",
    "X_train_sub,y_train,ind_x=DNN.get_training_data(X_train_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.4031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.2436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1238\n"
     ]
    }
   ],
   "source": [
    "DNN.make_network(activ='relu')\n",
    "DNN.train_model(X_train_sub,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#now scale all of the data.lo\n",
    "logX=take_log10(X)\n",
    "Xscale=(logX-X_train_avg)/X_train_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#predict on whole range\n",
    "pred=DNN.avg_predict_from_model(Xscale[:,ind_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc39926a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for k in range(Netf):\n",
    "    plt.subplot(4,2,k+1)\n",
    "    plt.plot_date(times,pred[:,k],'--',label='pred')\n",
    "    plt.plot_date(times,Xscale[:,-Netf+k],'-')#[:,ind_etf[k]])\n",
    "    plt.title(df_tot.columns[-Netf+k])\n",
    "    plt.plot_date([times[Nc]]*2,[-1,1],'k')\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So this is overfitting like crazy again! A simple linear regression would work better at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-e594243d8614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blah' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-0d599f0ec05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblah\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'blah' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Entire Market (^RUA)  Technology (IYW)  Basic Materials (IYM)  \\\n",
       "2017-09-05           1453.699951        147.656967              91.263222   \n",
       "2017-09-05           1453.699951        147.656967              91.263222   \n",
       "2017-09-06           1457.770020        147.955704              91.560776   \n",
       "2017-09-07           1456.829956        148.423721              91.699638   \n",
       "2017-09-08           1455.250000        147.039566              91.540939   \n",
       "\n",
       "            Consumer Goods (IYK)  Services (IYC)  Healthcare (IYH)  \\\n",
       "2017-09-05            120.192558      162.589981        168.935532   \n",
       "2017-09-05            120.192558      162.589981        168.935532   \n",
       "2017-09-06            120.400726      163.565002        169.720917   \n",
       "2017-09-07            120.509766      162.709366        171.331421   \n",
       "2017-09-08            120.301598      162.012939        172.077026   \n",
       "\n",
       "            Utilities (IDU)  \n",
       "2017-09-05       135.900024  \n",
       "2017-09-05       135.900024  \n",
       "2017-09-06       135.207962  \n",
       "2017-09-07       136.246048  \n",
       "2017-09-08       136.928207  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.tail().iloc[:,-Netf:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make fake data\n",
    "\n",
    "df_tail=df_tot.tail(n=100).iloc[:,-Netf:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#estimate mean difference.  \n",
    "df_final_inc=df_tail.diff(1).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_final=df_tail.iloc[-1].values\n",
    "df_ta=df_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1455.25    ,   147.039566,    91.540939,   120.301598,   162.012939,\n",
       "         172.077026,   136.928207])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "date=df_tail.index[-1]\n",
    "final_dates=pd.date_range(start=date,end='2017-12-31',freq='W')\n",
    "\n",
    "df_final=np.zeros((len(final_dates),7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nt = len(final_dates)\n",
    "for i in range(nt):\n",
    "    df_final[i]=df_final_val+i*df_final_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1455.25      ,   147.039566  ,    91.540939  ,   120.301598  ,\n",
       "          162.012939  ,   172.077026  ,   136.928207  ],\n",
       "       [ 1455.71252565,   147.15546714,    91.57471895,   120.32257737,\n",
       "          162.01303532,   172.25085535,   137.02246871],\n",
       "       [ 1456.17505129,   147.27136828,    91.6084989 ,   120.34355675,\n",
       "          162.01313165,   172.42468471,   137.11673041],\n",
       "       [ 1456.63757694,   147.38726942,    91.64227885,   120.36453612,\n",
       "          162.01322797,   172.59851406,   137.21099212],\n",
       "       [ 1457.10010259,   147.50317057,    91.6760588 ,   120.38551549,\n",
       "          162.01332429,   172.77234341,   137.30525383],\n",
       "       [ 1457.56262823,   147.61907171,    91.70983875,   120.40649487,\n",
       "          162.01342062,   172.94617277,   137.39951554],\n",
       "       [ 1458.02515388,   147.73497285,    91.7436187 ,   120.42747424,\n",
       "          162.01351694,   173.12000212,   137.49377724],\n",
       "       [ 1458.48767953,   147.85087399,    91.77739865,   120.44845362,\n",
       "          162.01361326,   173.29383147,   137.58803895],\n",
       "       [ 1458.95020517,   147.96677513,    91.8111786 ,   120.46943299,\n",
       "          162.01370959,   173.46766083,   137.68230066],\n",
       "       [ 1459.41273082,   148.08267627,    91.84495855,   120.49041236,\n",
       "          162.01380591,   173.64149018,   137.77656236],\n",
       "       [ 1459.87525646,   148.19857741,    91.87873849,   120.51139174,\n",
       "          162.01390223,   173.81531954,   137.87082407],\n",
       "       [ 1460.33778211,   148.31447856,    91.91251844,   120.53237111,\n",
       "          162.01399856,   173.98914889,   137.96508578],\n",
       "       [ 1460.80030776,   148.4303797 ,    91.94629839,   120.55335048,\n",
       "          162.01409488,   174.16297824,   138.05934748],\n",
       "       [ 1461.2628334 ,   148.54628084,    91.98007834,   120.57432986,\n",
       "          162.0141912 ,   174.3368076 ,   138.15360919],\n",
       "       [ 1461.72535905,   148.66218198,    92.01385829,   120.59530923,\n",
       "          162.01428753,   174.51063695,   138.2478709 ],\n",
       "       [ 1462.1878847 ,   148.77808312,    92.04763824,   120.61628861,\n",
       "          162.01438385,   174.6844663 ,   138.34213261],\n",
       "       [ 1462.65041034,   148.89398426,    92.08141819,   120.63726798,\n",
       "          162.01448017,   174.85829566,   138.43639431]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_final2=pd.DataFrame(df_final,index=final_dates,columns=df_tail.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_final2.to_csv('fake_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Entire Market (^RUA)', 'Technology (IYW)', 'Basic Materials (IYM)',\n",
       "       'Consumer Goods (IYK)', 'Services (IYC)', 'Healthcare (IYH)',\n",
       "       'Utilities (IDU)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Utilities (IDU)'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "PDX_finance_Mar2018.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
